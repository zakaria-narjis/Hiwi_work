{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/YuZhang-GitHub/Codebook_Learning_RL.git","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:39.047997Z","iopub.execute_input":"2023-11-06T19:11:39.048390Z","iopub.status.idle":"2023-11-06T19:11:41.811056Z","shell.execute_reply.started":"2023-11-06T19:11:39.048360Z","shell.execute_reply":"2023-11-06T19:11:41.809899Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Cloning into 'Codebook_Learning_RL'...\nremote: Enumerating objects: 77, done.\u001b[K\nremote: Counting objects: 100% (18/18), done.\u001b[K\nremote: Compressing objects: 100% (16/16), done.\u001b[K\nremote: Total 77 (delta 5), reused 0 (delta 0), pack-reused 59\u001b[K\nReceiving objects: 100% (77/77), 14.41 MiB | 17.20 MiB/s, done.\nResolving deltas: 100% (29/29), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/Codebook_Learning_RL')\nprint(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:41.813672Z","iopub.execute_input":"2023-11-06T19:11:41.814118Z","iopub.status.idle":"2023-11-06T19:11:41.820061Z","shell.execute_reply.started":"2023-11-06T19:11:41.814078Z","shell.execute_reply":"2023-11-06T19:11:41.819166Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"/kaggle/working/Codebook_Learning_RL\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport numpy as np\nimport copy\nimport pickle\nfrom scipy.optimize import linear_sum_assignment\nfrom DataPrep import dataPrep\nfrom env_ddpg import envCB\nfrom clustering import KMeans_only\nfrom function_lib import bf_gain_cal, corr_mining\nfrom DDPG_classes import Actor, Critic, OUNoise, init_weights","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:41.821414Z","iopub.execute_input":"2023-11-06T19:11:41.822153Z","iopub.status.idle":"2023-11-06T19:11:41.829714Z","shell.execute_reply.started":"2023-11-06T19:11:41.822104Z","shell.execute_reply":"2023-11-06T19:11:41.828927Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class envCB_(envCB):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.gain_history = [0]","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:41.831852Z","iopub.execute_input":"2023-11-06T19:11:41.832115Z","iopub.status.idle":"2023-11-06T19:11:41.839296Z","shell.execute_reply.started":"2023-11-06T19:11:41.832092Z","shell.execute_reply":"2023-11-06T19:11:41.838469Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# new_gain = torch.Tensor.cpu(CB_Env.achievement).detach().numpy().reshape((1, 1))\n# max_previous_gain = max(CB_Env.gain_history)\n#         if new_gain > max_previous_gain:\n#             CB_Env.gain_history.append(float(new_gain))                   \n#         else:\n#             CB_Env.gain_history.append(float(max_previous_gain))","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:41.840417Z","iopub.execute_input":"2023-11-06T19:11:41.840735Z","iopub.status.idle":"2023-11-06T19:11:41.849278Z","shell.execute_reply.started":"2023-11-06T19:11:41.840704Z","shell.execute_reply":"2023-11-06T19:11:41.848337Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"options = {\n        'gpu_idx': 0,\n        'num_ant': 32,\n        'num_bits': 4,\n        'num_NNs': 4,  # codebook size\n        'ch_sample_ratio': 0.5,\n        'num_loop': 400,  # outer loop\n        'target_update': 3,\n        'path': './grid1101-1400.mat',\n        'clustering_mode': 'random',\n    }\n\ntrain_opt = {\n        'state': 0,\n        'best_state': 0,\n        'num_iter': 100,  # inner loop\n        'tau': 1e-2,\n        'overall_iter': 1,\n        'replay_memory': [],\n        'replay_memory_size': 8192,\n        'minibatch_size': 1024,\n        'gamma': 0\n    }\nif not os.path.exists('beams/'):\n    os.mkdir('beams/')\n\nch = dataPrep(options['path'])\nch = np.concatenate((ch[:, :options['num_ant']],\n                     ch[:, int(ch.shape[1] / 2):int(ch.shape[1] / 2) + options['num_ant']]), axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:41.850276Z","iopub.execute_input":"2023-11-06T19:11:41.850556Z","iopub.status.idle":"2023-11-06T19:11:43.328947Z","shell.execute_reply.started":"2023-11-06T19:11:41.850533Z","shell.execute_reply":"2023-11-06T19:11:43.328078Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ndef train(actor_net,\n          critic_net,\n          actor_net_t,\n          critic_net_t,\n          ounoise,\n          env,\n          options,\n          train_options,\n          beam_id):\n    CB_Env = env\n    critic_optimizer = optim.Adam(critic_net.parameters(), lr=1e-3, weight_decay=1e-3)\n    actor_optimizer = optim.Adam(actor_net.parameters(), lr=1e-3, weight_decay=1e-2)\n    critic_criterion = nn.MSELoss()\n\n    if train_options['overall_iter'] == 1:\n        state = torch.zeros((1, options['num_ant'])).float().cuda()\n        print('Initial State Activated.')\n    else:\n        state = train_options['state']\n\n    # -------------- Training -------------- #\n    replay_memory = train_options['replay_memory']\n    iteration = 0\n    num_of_iter = train_options['num_iter']\n    while iteration < num_of_iter:\n\n        # Proto-action\n        action_pred = actor_net(state)\n        reward_pred, bf_gain_pred, action_quant_pred, state_1_pred = CB_Env.get_reward(action_pred)\n        reward_pred = torch.from_numpy(reward_pred).float().cuda()\n\n        # Exploration and Quantization Processing\n        action_pred_noisy = ounoise.get_action(action_pred,\n                                               t=train_options['overall_iter'])  # torch.Size([1, action_dim])\n        mat_dist = torch.abs(action_pred_noisy.reshape(options['num_ant'], 1) - options['ph_table_rep'])\n        action_quant = options['ph_table_rep'][range(options['num_ant']), torch.argmin(mat_dist, dim=1)].reshape(1, -1)\n\n        state_1, reward, bf_gain, terminal = CB_Env.step(action_quant)\n        reward = torch.from_numpy(reward).float().cuda()\n        action = action_quant.reshape((1, -1)).float().cuda()\n        \n        new_gain = torch.Tensor.cpu(CB_Env.achievement).detach().numpy().reshape((1, 1))\n        max_previous_gain = max(CB_Env.gain_history)\n        if new_gain > max_previous_gain:\n            CB_Env.gain_history.append(float(new_gain))                   \n        else:\n            CB_Env.gain_history.append(float(max_previous_gain))\n            \n        replay_memory.append((state, action, reward, state_1, terminal))\n        replay_memory.append((state, action_quant_pred, reward_pred, state_1_pred, terminal))\n        while len(replay_memory) > train_options['replay_memory_size']:\n            replay_memory.pop(0)\n\n        # -------------- Experience Replay -------------- #\n        minibatch = random.sample(replay_memory, min(len(replay_memory), train_options['minibatch_size']))\n\n        state_batch = torch.cat(tuple(d[0] for d in minibatch))  # torch.Size([*, state_dim])\n        action_batch = torch.cat(tuple(d[1] for d in minibatch))  # torch.Size([*, action_dim])\n        reward_batch = torch.cat(tuple(d[2] for d in minibatch))  # torch.Size([*, 1])\n        state_1_batch = torch.cat(tuple(d[3] for d in minibatch))  # torch.Size([*, state_dim])\n\n        state_batch = state_batch.detach()\n        action_batch = action_batch.detach()\n        reward_batch = reward_batch.detach()\n        state_1_batch = state_1_batch.detach()\n\n        if torch.cuda.is_available():\n            state_batch = state_batch.cuda()\n            action_batch = action_batch.cuda()\n            reward_batch = reward_batch.cuda()\n            state_1_batch = state_1_batch.cuda()\n\n        # Loss Calculation for Critic Network\n        next_actions = actor_net_t(state_1_batch)\n        next_Q = critic_net_t(state_1_batch, next_actions)\n        Q_prime = reward_batch + train_options['gamma'] * next_Q\n        Q_pred = critic_net(state_batch, action_batch)\n        critic_loss = critic_criterion(Q_pred, Q_prime.detach())\n\n        # Update Critic Network\n        critic_optimizer.zero_grad()\n        critic_loss.backward()\n        critic_optimizer.step()\n\n        # Loss Calculation for Actor Network\n        actor_loss = torch.mean(-critic_net(state_batch, actor_net(state_batch)))\n\n        # Update Actor Network\n        actor_optimizer.zero_grad()\n        actor_loss.backward()\n        actor_optimizer.step()\n\n        # UPDATE state, epsilon, target network, etc.\n        state = state_1\n        iteration += 1\n        train_options['overall_iter'] += 1  # global counter\n\n        # Update: Target Network\n        if train_options['overall_iter'] % options['target_update'] == 0:\n            actor_params = actor_net.state_dict()\n            critic_params = critic_net.state_dict()\n            actor_t_params = actor_net_t.state_dict()\n            critic_t_params = critic_net_t.state_dict()\n\n            for name in critic_params:\n                critic_params[name] = train_options['tau'] * critic_params[name].clone() + \\\n                                      (1 - train_options['tau']) * critic_t_params[name].clone()\n\n            critic_net_t.load_state_dict(critic_params)\n\n            for name in actor_params:\n                actor_params[name] = train_options['tau'] * actor_params[name].clone() + \\\n                                     (1 - train_options['tau']) * actor_t_params[name].clone()\n\n            actor_net_t.load_state_dict(actor_params)\n\n            # actor_net_t.load_state_dict(actor_net.state_dict())\n            # critic_net_t.load_state_dict(critic_net.state_dict())\n\n    if (train_options['overall_iter']-1)%500==0:\n        print(\n            \"Beam: %d, Iter: %d, Q: %.4f, Reward pred: %d, Reward: %d, BF Gain pred: %.2f, BF Gain: %.2f, Critic Loss: %.2f, Policy Loss: %.2f\" % \\\n            (beam_id, train_options['overall_iter'],\n             np.max(torch.Tensor.cpu(Q_pred.detach()).numpy().squeeze()),\n             int(torch.Tensor.cpu(reward_pred).numpy().squeeze()),\n             int(torch.Tensor.cpu(reward).numpy().squeeze()),\n             torch.Tensor.cpu(bf_gain_pred.detach()).numpy().squeeze(),\n             torch.Tensor.cpu(bf_gain.detach()).numpy().squeeze(),\n             torch.Tensor.cpu(critic_loss.detach()).numpy().squeeze(),\n             torch.Tensor.cpu(actor_loss.detach()).numpy().squeeze()))\n\n    # Training Communication Interface\n    train_options['replay_memory'] = replay_memory  # used for the next loop\n    train_options['state'] = state  # used for the next loop\n    train_options['best_state'] = CB_Env.best_bf_vec  # used for clustering and assignment\n\n    return train_options","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:43.330331Z","iopub.execute_input":"2023-11-06T19:11:43.330618Z","iopub.status.idle":"2023-11-06T19:11:43.359268Z","shell.execute_reply.started":"2023-11-06T19:11:43.330594Z","shell.execute_reply":"2023-11-06T19:11:43.358251Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"with torch.cuda.device(options['gpu_idx']):\n    u_classifier, sensing_beam = KMeans_only(ch, options['num_NNs'], n_bit=options['num_bits'], n_rand_beam=30)\n    np.save('sensing_beam.npy', sensing_beam)\n    sensing_beam = torch.from_numpy(sensing_beam).float().cuda()\n\n    filename = 'kmeans_model.sav'\n    pickle.dump(u_classifier, open(filename, 'wb'))\n\n    # Quantization settings\n    options['num_ph'] = 2 ** options['num_bits']\n    options['multi_step'] = torch.from_numpy(\n        np.linspace(int(-(options['num_ph'] - 2) / 2),\n                    int(options['num_ph'] / 2),\n                    num=options['num_ph'],\n                    endpoint=True)).type(dtype=torch.float32).reshape(1, -1).cuda()\n    options['pi'] = torch.tensor(np.pi).cuda()\n    options['ph_table'] = (2 * options['pi']) / options['num_ph'] * options['multi_step']\n    options['ph_table'].cuda()\n    options['ph_table_rep'] = options['ph_table'].repeat(options['num_ant'], 1)\n\n    # initialize DRL models\n    actor_net_list = []\n    critic_net_list = []\n    actor_net_t_list = []\n    critic_net_t_list = []\n    ounoise_list = []\n    env_list = []\n    train_opt_list = []\n\n    for beam_id in range(options['num_NNs']):\n        actor_net_list.append(Actor(options['num_ant'], options['num_ant']))\n        actor_net_t_list.append(Actor(options['num_ant'], options['num_ant']))\n        critic_net_list.append(Critic(2 * options['num_ant'], 1))\n        critic_net_t_list.append(Critic(2 * options['num_ant'], 1))\n        ounoise_list.append(OUNoise((1, options['num_ant'])))\n        env_list.append(envCB_(ch, options['num_ant'], options['num_bits'], beam_id, options))\n        train_opt_list.append(copy.deepcopy(train_opt))\n\n        actor_net_list[beam_id] = actor_net_list[beam_id].cuda()\n        actor_net_t_list[beam_id] = actor_net_t_list[beam_id].cuda()\n        critic_net_list[beam_id] = critic_net_list[beam_id].cuda()\n        critic_net_t_list[beam_id] = critic_net_t_list[beam_id].cuda()\n        actor_net_list[beam_id].apply(init_weights)\n        actor_net_t_list[beam_id].load_state_dict(actor_net_list[beam_id].state_dict())\n        critic_net_list[beam_id].apply(init_weights)\n        critic_net_t_list[beam_id].load_state_dict(critic_net_list[beam_id].state_dict())\n\n    # start_time = time.time()\n\n    # outer loop for randomly sampling users, emulating user dynamics\n    for sample_id in range(options['num_loop']):\n\n        # ---------- Sampling ---------- #\n        n_sample = int(ch.shape[0] * options['ch_sample_ratio'])\n        ch_sample_id = np.random.permutation(ch.shape[0])[0:n_sample]\n        ch_sample = torch.from_numpy(ch[ch_sample_id, :]).float().cuda()\n\n        # ---------- Clustering ---------- #\n#         start_time = time.time()\n\n        bf_mat_sample = bf_gain_cal(sensing_beam, ch_sample)\n        # print(\"Clustering -1 uses %s seconds.\" % (time.time() - start_time))\n        # start_time = time.time()\n        f_matrix = corr_mining(bf_mat_sample)\n        f_matrix_np = torch.Tensor.cpu(f_matrix).numpy()\n        # print(\"Clustering 0 uses %s seconds.\" % (time.time() - start_time))\n        # start_time = time.time()\n        labels = u_classifier.predict(np.transpose(f_matrix_np).astype(float))\n\n        # print(\"Clustering 1 uses %s seconds.\" % (time.time() - start_time))\n        # start_time = time.time()\n\n        user_group = []  # order: clusters\n        ch_group = []  # order: clusters\n        for ii in range(options['num_NNs']):\n            user_group.append(np.where(labels == ii)[0].tolist())\n            ch_group.append(ch_sample[user_group[ii], :])\n\n#         print(\"Clustering 2 uses %s seconds.\" % (time.time() - start_time))\n\n        # ---------- Assignment ---------- #\n#         start_time = time.time()\n\n        # best_state matrix\n        best_beam_mtx = torch.zeros((options['num_NNs'], 2 * options['num_ant'])).float().cuda()\n        for pp in range(options['num_NNs']):\n            best_beam_mtx[pp, :] = env_list[pp].best_bf_vec\n        gain_mtx = bf_gain_cal(best_beam_mtx, ch_sample)  # (n_beam, n_user)\n        for ii in range(options['num_NNs']):\n            if ii == 0:\n                cost_mtx = torch.mean(gain_mtx[:, user_group[ii]], dim=1).reshape(options['num_NNs'], -1)\n            else:\n                sub = torch.mean(gain_mtx[:, user_group[ii]], dim=1).reshape(options['num_NNs'], -1)\n                cost_mtx = torch.cat((cost_mtx, sub), dim=1)\n        cost_mtx = -torch.Tensor.cpu(cost_mtx).numpy()\n        row_ind, col_ind = linear_sum_assignment(cost_mtx)\n        assignment_record = dict(zip(row_ind.tolist(), col_ind.tolist()))  # key: network, value: cluster\n#         print(assignment_record)\n        for ii in range(options['num_NNs']):\n            env_list[ii].ch = ch_group[assignment_record[ii]]\n\n#         print(\"Assignment uses %s seconds.\" % (time.time() - start_time))\n        if (train_opt_list[beam_id]['overall_iter']-1)%500==0 or train_opt_list[beam_id]['overall_iter']==1:\n            start_time = time.time()\n        # ---------- Learning ---------- #\n        for beam_id in range(options['num_NNs']):\n            train_opt_list[beam_id] = train(actor_net_list[beam_id],\n                                            critic_net_list[beam_id],\n                                            actor_net_t_list[beam_id],\n                                            critic_net_t_list[beam_id],\n                                            ounoise_list[beam_id],\n                                            env_list[beam_id],\n                                            options,\n                                            train_opt_list[beam_id],\n                                            beam_id)\n        if (train_opt_list[beam_id]['overall_iter']-1)%500==0: \n            print(\"Training for 500 iteration for each Beam uses %s seconds.\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:11:43.360592Z","iopub.execute_input":"2023-11-06T19:11:43.360904Z","iopub.status.idle":"2023-11-06T19:47:10.238202Z","shell.execute_reply.started":"2023-11-06T19:11:43.360880Z","shell.execute_reply":"2023-11-06T19:47:10.237176Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"EGC bf gain:  231.17094\nEGC bf gain:  231.17094\nEGC bf gain:  231.17094\nEGC bf gain:  231.17094\nInitial State Activated.\nInitial State Activated.\nInitial State Activated.\nInitial State Activated.\nBeam: 0, Iter: 501, Q: 1.5523, Reward pred: -1, Reward: 1, BF Gain pred: 1.06, BF Gain: 4.83, Critic Loss: 0.22, Policy Loss: -1.84\nBeam: 1, Iter: 501, Q: 1.4398, Reward pred: 1, Reward: 1, BF Gain pred: 7.57, BF Gain: 10.63, Critic Loss: 0.31, Policy Loss: -2.50\nBeam: 2, Iter: 501, Q: 1.6231, Reward pred: 1, Reward: 1, BF Gain pred: 1.28, BF Gain: 2.51, Critic Loss: 0.17, Policy Loss: -2.48\nBeam: 3, Iter: 501, Q: 1.4976, Reward pred: -1, Reward: 1, BF Gain pred: 1.84, BF Gain: 6.15, Critic Loss: 0.32, Policy Loss: -2.22\nTraining for 500 iteration for each Beam uses 21.85211706161499 seconds.\nBeam: 0, Iter: 1001, Q: 1.7704, Reward pred: -1, Reward: -1, BF Gain pred: 5.15, BF Gain: 8.53, Critic Loss: 0.14, Policy Loss: -1.87\nBeam: 1, Iter: 1001, Q: 2.5628, Reward pred: 1, Reward: 1, BF Gain pred: 19.09, BF Gain: 13.81, Critic Loss: 0.19, Policy Loss: -3.00\nBeam: 2, Iter: 1001, Q: 1.5108, Reward pred: -1, Reward: -1, BF Gain pred: 11.72, BF Gain: 2.02, Critic Loss: 0.09, Policy Loss: -2.11\nBeam: 3, Iter: 1001, Q: 2.0552, Reward pred: 1, Reward: -1, BF Gain pred: 9.73, BF Gain: 6.33, Critic Loss: 0.23, Policy Loss: -2.65\nTraining for 500 iteration for each Beam uses 24.649751901626587 seconds.\nBeam: 0, Iter: 1501, Q: 1.7189, Reward pred: 1, Reward: 1, BF Gain pred: 23.05, BF Gain: 14.56, Critic Loss: 0.08, Policy Loss: -1.88\nBeam: 1, Iter: 1501, Q: 2.6846, Reward pred: -1, Reward: -1, BF Gain pred: 21.21, BF Gain: 9.86, Critic Loss: 0.11, Policy Loss: -2.42\nBeam: 2, Iter: 1501, Q: 1.6193, Reward pred: 1, Reward: -1, BF Gain pred: 6.00, BF Gain: 2.70, Critic Loss: 0.07, Policy Loss: -1.71\nBeam: 3, Iter: 1501, Q: 1.5763, Reward pred: -1, Reward: 1, BF Gain pred: 4.37, BF Gain: 19.21, Critic Loss: 0.13, Policy Loss: -2.45\nTraining for 500 iteration for each Beam uses 24.796173095703125 seconds.\nBeam: 0, Iter: 2001, Q: 1.3772, Reward pred: -1, Reward: -1, BF Gain pred: 12.94, BF Gain: 5.81, Critic Loss: 0.07, Policy Loss: -1.64\nBeam: 1, Iter: 2001, Q: 1.9475, Reward pred: -1, Reward: 1, BF Gain pred: 34.70, BF Gain: 48.76, Critic Loss: 0.10, Policy Loss: -2.18\nBeam: 2, Iter: 2001, Q: 2.1320, Reward pred: 1, Reward: 1, BF Gain pred: 18.65, BF Gain: 4.87, Critic Loss: 0.06, Policy Loss: -1.78\nBeam: 3, Iter: 2001, Q: 1.4185, Reward pred: -1, Reward: -1, BF Gain pred: 2.47, BF Gain: 4.42, Critic Loss: 0.12, Policy Loss: -2.24\nTraining for 500 iteration for each Beam uses 24.989044427871704 seconds.\nBeam: 0, Iter: 2501, Q: 1.3820, Reward pred: 1, Reward: -1, BF Gain pred: 11.35, BF Gain: 1.85, Critic Loss: 0.06, Policy Loss: -1.49\nBeam: 1, Iter: 2501, Q: 1.4054, Reward pred: 1, Reward: -1, BF Gain pred: 34.77, BF Gain: 3.95, Critic Loss: 0.07, Policy Loss: -2.07\nBeam: 2, Iter: 2501, Q: 1.3287, Reward pred: -1, Reward: -1, BF Gain pred: 25.36, BF Gain: 17.00, Critic Loss: 0.05, Policy Loss: -1.54\nBeam: 3, Iter: 2501, Q: 1.7243, Reward pred: 1, Reward: 1, BF Gain pred: 7.72, BF Gain: 3.09, Critic Loss: 0.10, Policy Loss: -2.18\nTraining for 500 iteration for each Beam uses 24.989837169647217 seconds.\nBeam: 0, Iter: 3001, Q: 1.5306, Reward pred: 1, Reward: -1, BF Gain pred: 38.99, BF Gain: 34.65, Critic Loss: 0.10, Policy Loss: -1.42\nBeam: 1, Iter: 3001, Q: 1.3647, Reward pred: 1, Reward: -1, BF Gain pred: 30.43, BF Gain: 1.87, Critic Loss: 0.06, Policy Loss: -2.16\nBeam: 2, Iter: 3001, Q: 1.4499, Reward pred: 1, Reward: -1, BF Gain pred: 38.19, BF Gain: 9.72, Critic Loss: 0.05, Policy Loss: -1.54\nBeam: 3, Iter: 3001, Q: 1.4476, Reward pred: 1, Reward: -1, BF Gain pred: 21.32, BF Gain: 5.93, Critic Loss: 0.08, Policy Loss: -2.26\nTraining for 500 iteration for each Beam uses 24.933185338974 seconds.\nBeam: 0, Iter: 3501, Q: 1.3928, Reward pred: 1, Reward: -1, BF Gain pred: 48.11, BF Gain: 14.10, Critic Loss: 0.09, Policy Loss: -1.48\nBeam: 1, Iter: 3501, Q: 1.4744, Reward pred: -1, Reward: -1, BF Gain pred: 16.68, BF Gain: 1.26, Critic Loss: 0.06, Policy Loss: -2.09\nBeam: 2, Iter: 3501, Q: 1.2509, Reward pred: -1, Reward: -1, BF Gain pred: 45.04, BF Gain: 8.76, Critic Loss: 0.06, Policy Loss: -1.49\nBeam: 3, Iter: 3501, Q: 1.4285, Reward pred: -1, Reward: 1, BF Gain pred: 1.68, BF Gain: 5.46, Critic Loss: 0.08, Policy Loss: -2.10\nTraining for 500 iteration for each Beam uses 25.405147314071655 seconds.\nBeam: 0, Iter: 4001, Q: 1.4714, Reward pred: -1, Reward: -1, BF Gain pred: 73.62, BF Gain: 45.58, Critic Loss: 0.06, Policy Loss: -1.43\nBeam: 1, Iter: 4001, Q: 1.3376, Reward pred: 1, Reward: 1, BF Gain pred: 96.16, BF Gain: 54.29, Critic Loss: 0.05, Policy Loss: -1.89\nBeam: 2, Iter: 4001, Q: 1.3644, Reward pred: 1, Reward: -1, BF Gain pred: 70.15, BF Gain: 17.69, Critic Loss: 0.08, Policy Loss: -1.42\nBeam: 3, Iter: 4001, Q: 1.3991, Reward pred: 1, Reward: 1, BF Gain pred: 9.61, BF Gain: 17.56, Critic Loss: 0.07, Policy Loss: -2.00\nTraining for 500 iteration for each Beam uses 24.786559104919434 seconds.\nBeam: 0, Iter: 4501, Q: 1.3757, Reward pred: 1, Reward: -1, BF Gain pred: 79.76, BF Gain: 15.67, Critic Loss: 0.08, Policy Loss: -1.39\nBeam: 1, Iter: 4501, Q: 1.3049, Reward pred: -1, Reward: -1, BF Gain pred: 73.07, BF Gain: 24.41, Critic Loss: 0.05, Policy Loss: -1.81\nBeam: 2, Iter: 4501, Q: 1.3473, Reward pred: 1, Reward: -1, BF Gain pred: 43.83, BF Gain: 10.02, Critic Loss: 0.05, Policy Loss: -1.48\nBeam: 3, Iter: 4501, Q: 1.5443, Reward pred: -1, Reward: -1, BF Gain pred: 7.25, BF Gain: 2.18, Critic Loss: 0.08, Policy Loss: -1.97\nTraining for 500 iteration for each Beam uses 25.105130434036255 seconds.\nBeam: 0, Iter: 5001, Q: 1.3527, Reward pred: 1, Reward: -1, BF Gain pred: 109.71, BF Gain: 25.64, Critic Loss: 0.09, Policy Loss: -1.26\nBeam: 1, Iter: 5001, Q: 1.3585, Reward pred: 1, Reward: -1, BF Gain pred: 102.31, BF Gain: 20.12, Critic Loss: 0.06, Policy Loss: -1.63\nBeam: 2, Iter: 5001, Q: 1.4183, Reward pred: 1, Reward: -1, BF Gain pred: 58.49, BF Gain: 17.61, Critic Loss: 0.07, Policy Loss: -1.26\nBeam: 3, Iter: 5001, Q: 1.6195, Reward pred: -1, Reward: 1, BF Gain pred: 2.13, BF Gain: 9.01, Critic Loss: 0.11, Policy Loss: -1.95\nTraining for 500 iteration for each Beam uses 25.360385179519653 seconds.\nBeam: 0, Iter: 5501, Q: 1.4874, Reward pred: 1, Reward: -1, BF Gain pred: 78.88, BF Gain: 12.15, Critic Loss: 0.11, Policy Loss: -1.16\nBeam: 1, Iter: 5501, Q: 1.5030, Reward pred: -1, Reward: -1, BF Gain pred: 125.38, BF Gain: 44.00, Critic Loss: 0.09, Policy Loss: -1.64\nBeam: 2, Iter: 5501, Q: 1.8707, Reward pred: 1, Reward: -1, BF Gain pred: 75.13, BF Gain: 23.58, Critic Loss: 0.06, Policy Loss: -1.18\nBeam: 3, Iter: 5501, Q: 1.4587, Reward pred: 1, Reward: -1, BF Gain pred: 46.47, BF Gain: 13.99, Critic Loss: 0.09, Policy Loss: -1.69\nTraining for 500 iteration for each Beam uses 26.204458475112915 seconds.\nBeam: 0, Iter: 6001, Q: 1.3119, Reward pred: -1, Reward: -1, BF Gain pred: 157.94, BF Gain: 52.08, Critic Loss: 0.10, Policy Loss: -1.11\nBeam: 1, Iter: 6001, Q: 1.6472, Reward pred: 1, Reward: -1, BF Gain pred: 134.43, BF Gain: 44.61, Critic Loss: 0.09, Policy Loss: -1.55\nBeam: 2, Iter: 6001, Q: 1.3308, Reward pred: 1, Reward: -1, BF Gain pred: 64.49, BF Gain: 23.65, Critic Loss: 0.04, Policy Loss: -1.32\nBeam: 3, Iter: 6001, Q: 1.5051, Reward pred: 1, Reward: -1, BF Gain pred: 64.30, BF Gain: 12.05, Critic Loss: 0.07, Policy Loss: -1.93\nTraining for 500 iteration for each Beam uses 25.74522638320923 seconds.\nBeam: 0, Iter: 6501, Q: 1.3926, Reward pred: -1, Reward: -1, BF Gain pred: 76.40, BF Gain: 43.30, Critic Loss: 0.13, Policy Loss: -1.13\nBeam: 1, Iter: 6501, Q: 1.5320, Reward pred: -1, Reward: -1, BF Gain pred: 130.02, BF Gain: 62.63, Critic Loss: 0.10, Policy Loss: -1.23\nBeam: 2, Iter: 6501, Q: 1.2981, Reward pred: -1, Reward: -1, BF Gain pred: 64.36, BF Gain: 12.16, Critic Loss: 0.04, Policy Loss: -1.22\nBeam: 3, Iter: 6501, Q: 1.4237, Reward pred: -1, Reward: -1, BF Gain pred: 32.34, BF Gain: 20.11, Critic Loss: 0.07, Policy Loss: -2.02\nTraining for 500 iteration for each Beam uses 25.37950110435486 seconds.\nBeam: 0, Iter: 7001, Q: 1.4507, Reward pred: -1, Reward: -1, BF Gain pred: 57.81, BF Gain: 28.90, Critic Loss: 0.18, Policy Loss: -0.73\nBeam: 1, Iter: 7001, Q: 1.7328, Reward pred: -1, Reward: -1, BF Gain pred: 77.03, BF Gain: 40.29, Critic Loss: 0.28, Policy Loss: -1.36\nBeam: 2, Iter: 7001, Q: 1.3463, Reward pred: 1, Reward: -1, BF Gain pred: 74.24, BF Gain: 27.46, Critic Loss: 0.05, Policy Loss: -1.05\nBeam: 3, Iter: 7001, Q: 1.7784, Reward pred: -1, Reward: -1, BF Gain pred: 6.85, BF Gain: 6.56, Critic Loss: 0.37, Policy Loss: -0.84\nTraining for 500 iteration for each Beam uses 25.22212028503418 seconds.\nBeam: 0, Iter: 7501, Q: 1.3890, Reward pred: -1, Reward: -1, BF Gain pred: 78.68, BF Gain: 19.42, Critic Loss: 0.17, Policy Loss: -0.83\nBeam: 1, Iter: 7501, Q: 1.4940, Reward pred: -1, Reward: -1, BF Gain pred: 153.90, BF Gain: 31.99, Critic Loss: 0.07, Policy Loss: -1.63\nBeam: 2, Iter: 7501, Q: 1.4614, Reward pred: 1, Reward: -1, BF Gain pred: 89.74, BF Gain: 37.56, Critic Loss: 0.06, Policy Loss: -1.24\nBeam: 3, Iter: 7501, Q: 1.5266, Reward pred: -1, Reward: -1, BF Gain pred: 74.47, BF Gain: 28.99, Critic Loss: 0.12, Policy Loss: -1.86\nTraining for 500 iteration for each Beam uses 25.339432954788208 seconds.\nBeam: 0, Iter: 8001, Q: 1.4366, Reward pred: 1, Reward: -1, BF Gain pred: 164.24, BF Gain: 65.23, Critic Loss: 0.20, Policy Loss: -0.80\nBeam: 1, Iter: 8001, Q: 2.2955, Reward pred: 1, Reward: -1, BF Gain pred: 146.59, BF Gain: 71.99, Critic Loss: 0.05, Policy Loss: -1.57\nBeam: 2, Iter: 8001, Q: 1.3919, Reward pred: 1, Reward: -1, BF Gain pred: 83.75, BF Gain: 11.67, Critic Loss: 0.07, Policy Loss: -1.00\nBeam: 3, Iter: 8001, Q: 1.3775, Reward pred: 1, Reward: -1, BF Gain pred: 83.40, BF Gain: 38.15, Critic Loss: 0.07, Policy Loss: -2.00\nTraining for 500 iteration for each Beam uses 25.615735292434692 seconds.\nBeam: 0, Iter: 8501, Q: 1.4053, Reward pred: 1, Reward: -1, BF Gain pred: 146.14, BF Gain: 12.60, Critic Loss: 0.16, Policy Loss: -0.92\nBeam: 1, Iter: 8501, Q: 1.7283, Reward pred: 1, Reward: -1, BF Gain pred: 145.93, BF Gain: 29.27, Critic Loss: 0.10, Policy Loss: -1.15\nBeam: 2, Iter: 8501, Q: 2.4491, Reward pred: -1, Reward: -1, BF Gain pred: 78.36, BF Gain: 32.03, Critic Loss: 0.05, Policy Loss: -1.13\nBeam: 3, Iter: 8501, Q: 1.8544, Reward pred: 1, Reward: -1, BF Gain pred: 77.14, BF Gain: 28.77, Critic Loss: 0.33, Policy Loss: -1.72\nTraining for 500 iteration for each Beam uses 25.536815643310547 seconds.\nBeam: 0, Iter: 9001, Q: 1.3227, Reward pred: 1, Reward: -1, BF Gain pred: 152.40, BF Gain: 35.23, Critic Loss: 0.19, Policy Loss: -0.81\nBeam: 1, Iter: 9001, Q: 1.4473, Reward pred: 1, Reward: -1, BF Gain pred: 173.50, BF Gain: 65.20, Critic Loss: 0.11, Policy Loss: -1.21\nBeam: 2, Iter: 9001, Q: 1.1691, Reward pred: -1, Reward: -1, BF Gain pred: 78.35, BF Gain: 17.11, Critic Loss: 0.07, Policy Loss: -1.03\nBeam: 3, Iter: 9001, Q: 1.7263, Reward pred: -1, Reward: -1, BF Gain pred: 53.35, BF Gain: 4.62, Critic Loss: 0.14, Policy Loss: -1.78\nTraining for 500 iteration for each Beam uses 25.406604290008545 seconds.\nBeam: 0, Iter: 9501, Q: 1.3432, Reward pred: 1, Reward: -1, BF Gain pred: 201.96, BF Gain: 21.12, Critic Loss: 0.21, Policy Loss: -0.55\nBeam: 1, Iter: 9501, Q: 1.6587, Reward pred: -1, Reward: -1, BF Gain pred: 149.09, BF Gain: 33.40, Critic Loss: 0.14, Policy Loss: -1.16\nBeam: 2, Iter: 9501, Q: 1.4523, Reward pred: -1, Reward: -1, BF Gain pred: 77.14, BF Gain: 40.33, Critic Loss: 0.06, Policy Loss: -1.10\nBeam: 3, Iter: 9501, Q: 1.6193, Reward pred: -1, Reward: -1, BF Gain pred: 44.80, BF Gain: 12.20, Critic Loss: 0.07, Policy Loss: -1.97\nTraining for 500 iteration for each Beam uses 25.514415502548218 seconds.\nBeam: 0, Iter: 10001, Q: 1.5114, Reward pred: 1, Reward: -1, BF Gain pred: 168.59, BF Gain: 77.23, Critic Loss: 0.15, Policy Loss: -0.76\nBeam: 1, Iter: 10001, Q: 1.4322, Reward pred: -1, Reward: -1, BF Gain pred: 161.23, BF Gain: 28.59, Critic Loss: 0.14, Policy Loss: -0.89\nBeam: 2, Iter: 10001, Q: 1.4005, Reward pred: -1, Reward: -1, BF Gain pred: 73.69, BF Gain: 25.44, Critic Loss: 0.06, Policy Loss: -1.14\nBeam: 3, Iter: 10001, Q: 1.6812, Reward pred: 1, Reward: -1, BF Gain pred: 104.53, BF Gain: 13.33, Critic Loss: 0.11, Policy Loss: -1.50\nTraining for 500 iteration for each Beam uses 25.52158236503601 seconds.\nBeam: 0, Iter: 10501, Q: 1.3548, Reward pred: 1, Reward: -1, BF Gain pred: 171.90, BF Gain: 75.89, Critic Loss: 0.17, Policy Loss: -0.58\nBeam: 1, Iter: 10501, Q: 1.4511, Reward pred: 1, Reward: -1, BF Gain pred: 183.15, BF Gain: 61.34, Critic Loss: 0.09, Policy Loss: -1.23\nBeam: 2, Iter: 10501, Q: 1.3269, Reward pred: -1, Reward: -1, BF Gain pred: 83.72, BF Gain: 29.88, Critic Loss: 0.12, Policy Loss: -0.74\nBeam: 3, Iter: 10501, Q: 1.5444, Reward pred: 1, Reward: -1, BF Gain pred: 112.05, BF Gain: 27.42, Critic Loss: 0.09, Policy Loss: -1.92\nTraining for 500 iteration for each Beam uses 25.560986757278442 seconds.\nBeam: 0, Iter: 11001, Q: 1.5262, Reward pred: 1, Reward: -1, BF Gain pred: 167.51, BF Gain: 39.15, Critic Loss: 0.13, Policy Loss: -0.82\nBeam: 1, Iter: 11001, Q: 1.5137, Reward pred: -1, Reward: -1, BF Gain pred: 158.82, BF Gain: 64.52, Critic Loss: 0.07, Policy Loss: -1.37\nBeam: 2, Iter: 11001, Q: 1.3953, Reward pred: -1, Reward: -1, BF Gain pred: 87.97, BF Gain: 25.65, Critic Loss: 0.08, Policy Loss: -0.86\nBeam: 3, Iter: 11001, Q: 1.5746, Reward pred: 1, Reward: -1, BF Gain pred: 98.58, BF Gain: 17.12, Critic Loss: 0.11, Policy Loss: -1.86\nTraining for 500 iteration for each Beam uses 25.546392679214478 seconds.\nBeam: 0, Iter: 11501, Q: 1.4249, Reward pred: -1, Reward: -1, BF Gain pred: 146.55, BF Gain: 67.01, Critic Loss: 0.11, Policy Loss: -0.78\nBeam: 1, Iter: 11501, Q: 0.8854, Reward pred: 1, Reward: -1, BF Gain pred: 177.90, BF Gain: 38.20, Critic Loss: 0.31, Policy Loss: -0.57\nBeam: 2, Iter: 11501, Q: 1.4211, Reward pred: -1, Reward: -1, BF Gain pred: 83.09, BF Gain: 18.69, Critic Loss: 0.06, Policy Loss: -1.00\nBeam: 3, Iter: 11501, Q: 1.4263, Reward pred: -1, Reward: -1, BF Gain pred: 86.92, BF Gain: 21.98, Critic Loss: 0.17, Policy Loss: -1.28\nTraining for 500 iteration for each Beam uses 25.722532510757446 seconds.\nBeam: 0, Iter: 12001, Q: 1.3767, Reward pred: -1, Reward: -1, BF Gain pred: 128.63, BF Gain: 40.03, Critic Loss: 0.08, Policy Loss: -0.83\nBeam: 1, Iter: 12001, Q: 1.4690, Reward pred: -1, Reward: -1, BF Gain pred: 184.41, BF Gain: 97.25, Critic Loss: 0.08, Policy Loss: -1.09\nBeam: 2, Iter: 12001, Q: 1.2301, Reward pred: 1, Reward: -1, BF Gain pred: 78.75, BF Gain: 20.99, Critic Loss: 0.05, Policy Loss: -1.05\nBeam: 3, Iter: 12001, Q: 0.9817, Reward pred: 1, Reward: -1, BF Gain pred: 70.64, BF Gain: 14.33, Critic Loss: 0.16, Policy Loss: -0.79\nTraining for 500 iteration for each Beam uses 25.766640424728394 seconds.\nBeam: 0, Iter: 12501, Q: 1.3769, Reward pred: 1, Reward: -1, BF Gain pred: 143.49, BF Gain: 34.99, Critic Loss: 0.11, Policy Loss: -0.82\nBeam: 1, Iter: 12501, Q: 1.5875, Reward pred: 1, Reward: -1, BF Gain pred: 182.18, BF Gain: 47.36, Critic Loss: 0.21, Policy Loss: -0.97\nBeam: 2, Iter: 12501, Q: 1.4144, Reward pred: 1, Reward: -1, BF Gain pred: 82.31, BF Gain: 51.61, Critic Loss: 0.05, Policy Loss: -1.09\nBeam: 3, Iter: 12501, Q: 1.6432, Reward pred: 1, Reward: -1, BF Gain pred: 89.56, BF Gain: 38.60, Critic Loss: 0.18, Policy Loss: -0.72\nTraining for 500 iteration for each Beam uses 26.984481811523438 seconds.\nBeam: 0, Iter: 13001, Q: 1.4700, Reward pred: 1, Reward: -1, BF Gain pred: 175.40, BF Gain: 23.21, Critic Loss: 0.08, Policy Loss: -0.75\nBeam: 1, Iter: 13001, Q: 1.4682, Reward pred: 1, Reward: -1, BF Gain pred: 188.68, BF Gain: 64.57, Critic Loss: 0.09, Policy Loss: -1.11\nBeam: 2, Iter: 13001, Q: 1.3249, Reward pred: -1, Reward: -1, BF Gain pred: 65.37, BF Gain: 24.83, Critic Loss: 0.05, Policy Loss: -1.03\nBeam: 3, Iter: 13001, Q: 1.4260, Reward pred: -1, Reward: -1, BF Gain pred: 88.84, BF Gain: 73.90, Critic Loss: 0.14, Policy Loss: -0.85\nTraining for 500 iteration for each Beam uses 26.449979782104492 seconds.\nBeam: 0, Iter: 13501, Q: 1.6368, Reward pred: -1, Reward: -1, BF Gain pred: 191.48, BF Gain: 63.37, Critic Loss: 0.08, Policy Loss: -0.85\nBeam: 1, Iter: 13501, Q: 1.1415, Reward pred: 1, Reward: -1, BF Gain pred: 171.91, BF Gain: 24.84, Critic Loss: 0.22, Policy Loss: -0.75\nBeam: 2, Iter: 13501, Q: 1.4982, Reward pred: 1, Reward: -1, BF Gain pred: 82.58, BF Gain: 28.79, Critic Loss: 0.07, Policy Loss: -1.03\nBeam: 3, Iter: 13501, Q: 1.5955, Reward pred: 1, Reward: -1, BF Gain pred: 95.57, BF Gain: 21.38, Critic Loss: 0.11, Policy Loss: -1.04\nTraining for 500 iteration for each Beam uses 26.337722301483154 seconds.\nBeam: 0, Iter: 14001, Q: 1.6263, Reward pred: 1, Reward: -1, BF Gain pred: 181.21, BF Gain: 112.72, Critic Loss: 0.07, Policy Loss: -0.82\nBeam: 1, Iter: 14001, Q: 1.5642, Reward pred: 1, Reward: -1, BF Gain pred: 194.79, BF Gain: 61.98, Critic Loss: 0.12, Policy Loss: -0.89\nBeam: 2, Iter: 14001, Q: 1.7693, Reward pred: 1, Reward: -1, BF Gain pred: 81.71, BF Gain: 18.39, Critic Loss: 0.04, Policy Loss: -0.94\nBeam: 3, Iter: 14001, Q: 1.4749, Reward pred: -1, Reward: -1, BF Gain pred: 102.40, BF Gain: 22.60, Critic Loss: 0.07, Policy Loss: -1.22\nTraining for 500 iteration for each Beam uses 26.5290048122406 seconds.\nBeam: 0, Iter: 14501, Q: 1.4199, Reward pred: -1, Reward: -1, BF Gain pred: 179.19, BF Gain: 61.36, Critic Loss: 0.07, Policy Loss: -0.84\nBeam: 1, Iter: 14501, Q: 1.4738, Reward pred: -1, Reward: -1, BF Gain pred: 203.30, BF Gain: 30.26, Critic Loss: 0.09, Policy Loss: -1.12\nBeam: 2, Iter: 14501, Q: 1.5709, Reward pred: 1, Reward: -1, BF Gain pred: 85.85, BF Gain: 20.83, Critic Loss: 0.10, Policy Loss: -0.82\nBeam: 3, Iter: 14501, Q: 1.7540, Reward pred: 1, Reward: -1, BF Gain pred: 130.34, BF Gain: 59.54, Critic Loss: 0.08, Policy Loss: -1.15\nTraining for 500 iteration for each Beam uses 26.44617223739624 seconds.\nBeam: 0, Iter: 15001, Q: 1.6643, Reward pred: 1, Reward: -1, BF Gain pred: 202.97, BF Gain: 44.84, Critic Loss: 0.08, Policy Loss: -0.83\nBeam: 1, Iter: 15001, Q: 1.5070, Reward pred: 1, Reward: -1, BF Gain pred: 195.69, BF Gain: 71.04, Critic Loss: 0.09, Policy Loss: -1.04\nBeam: 2, Iter: 15001, Q: 1.4951, Reward pred: -1, Reward: -1, BF Gain pred: 74.55, BF Gain: 5.46, Critic Loss: 0.08, Policy Loss: -0.92\nBeam: 3, Iter: 15001, Q: 1.6168, Reward pred: -1, Reward: -1, BF Gain pred: 104.38, BF Gain: 30.78, Critic Loss: 0.18, Policy Loss: -0.88\nTraining for 500 iteration for each Beam uses 26.12397575378418 seconds.\nBeam: 0, Iter: 15501, Q: 1.9957, Reward pred: 1, Reward: -1, BF Gain pred: 186.44, BF Gain: 15.73, Critic Loss: 0.08, Policy Loss: -0.73\nBeam: 1, Iter: 15501, Q: 1.5802, Reward pred: -1, Reward: -1, BF Gain pred: 180.27, BF Gain: 56.95, Critic Loss: 0.07, Policy Loss: -1.09\nBeam: 2, Iter: 15501, Q: 1.2953, Reward pred: 1, Reward: -1, BF Gain pred: 80.69, BF Gain: 18.92, Critic Loss: 0.06, Policy Loss: -0.98\nBeam: 3, Iter: 15501, Q: 1.5724, Reward pred: -1, Reward: -1, BF Gain pred: 101.70, BF Gain: 30.62, Critic Loss: 0.08, Policy Loss: -1.05\nTraining for 500 iteration for each Beam uses 26.063632249832153 seconds.\nBeam: 0, Iter: 16001, Q: 1.5490, Reward pred: -1, Reward: -1, BF Gain pred: 202.11, BF Gain: 98.63, Critic Loss: 0.09, Policy Loss: -0.58\nBeam: 1, Iter: 16001, Q: 1.6949, Reward pred: -1, Reward: -1, BF Gain pred: 178.29, BF Gain: 104.26, Critic Loss: 0.06, Policy Loss: -1.06\nBeam: 2, Iter: 16001, Q: 1.3835, Reward pred: 1, Reward: -1, BF Gain pred: 95.83, BF Gain: 43.83, Critic Loss: 0.05, Policy Loss: -1.03\nBeam: 3, Iter: 16001, Q: 1.6674, Reward pred: -1, Reward: -1, BF Gain pred: 101.21, BF Gain: 47.08, Critic Loss: 0.10, Policy Loss: -1.08\nTraining for 500 iteration for each Beam uses 26.504774570465088 seconds.\nBeam: 0, Iter: 16501, Q: 1.4441, Reward pred: 1, Reward: -1, BF Gain pred: 214.18, BF Gain: 57.37, Critic Loss: 0.09, Policy Loss: -0.81\nBeam: 1, Iter: 16501, Q: 1.3955, Reward pred: -1, Reward: -1, BF Gain pred: 190.13, BF Gain: 43.37, Critic Loss: 0.08, Policy Loss: -0.96\nBeam: 2, Iter: 16501, Q: 2.3072, Reward pred: 1, Reward: -1, BF Gain pred: 94.76, BF Gain: 31.23, Critic Loss: 0.07, Policy Loss: -1.07\nBeam: 3, Iter: 16501, Q: 1.5215, Reward pred: -1, Reward: -1, BF Gain pred: 112.91, BF Gain: 10.66, Critic Loss: 0.07, Policy Loss: -1.04\nTraining for 500 iteration for each Beam uses 26.88034415245056 seconds.\nBeam: 0, Iter: 17001, Q: 1.7716, Reward pred: -1, Reward: -1, BF Gain pred: 198.00, BF Gain: 26.97, Critic Loss: 0.09, Policy Loss: -0.76\nBeam: 1, Iter: 17001, Q: 1.4162, Reward pred: -1, Reward: -1, BF Gain pred: 193.77, BF Gain: 68.26, Critic Loss: 0.08, Policy Loss: -1.00\nBeam: 2, Iter: 17001, Q: 1.2962, Reward pred: 1, Reward: -1, BF Gain pred: 83.88, BF Gain: 26.32, Critic Loss: 0.05, Policy Loss: -1.16\nBeam: 3, Iter: 17001, Q: 1.6355, Reward pred: 1, Reward: -1, BF Gain pred: 128.92, BF Gain: 42.17, Critic Loss: 0.10, Policy Loss: -0.92\nTraining for 500 iteration for each Beam uses 26.96635341644287 seconds.\nBeam: 0, Iter: 17501, Q: 1.4074, Reward pred: -1, Reward: -1, BF Gain pred: 202.66, BF Gain: 83.07, Critic Loss: 0.06, Policy Loss: -0.84\nBeam: 1, Iter: 17501, Q: 1.5119, Reward pred: 1, Reward: -1, BF Gain pred: 205.64, BF Gain: 76.34, Critic Loss: 0.06, Policy Loss: -1.10\nBeam: 2, Iter: 17501, Q: 1.7230, Reward pred: -1, Reward: -1, BF Gain pred: 81.66, BF Gain: 17.75, Critic Loss: 0.09, Policy Loss: -0.88\nBeam: 3, Iter: 17501, Q: 1.5064, Reward pred: 1, Reward: -1, BF Gain pred: 135.70, BF Gain: 50.68, Critic Loss: 0.08, Policy Loss: -1.03\nTraining for 500 iteration for each Beam uses 27.25562810897827 seconds.\nBeam: 0, Iter: 18001, Q: 1.2164, Reward pred: 1, Reward: -1, BF Gain pred: 202.53, BF Gain: 60.02, Critic Loss: 0.08, Policy Loss: -0.95\nBeam: 1, Iter: 18001, Q: 1.4352, Reward pred: 1, Reward: -1, BF Gain pred: 204.74, BF Gain: 83.19, Critic Loss: 0.05, Policy Loss: -1.05\nBeam: 2, Iter: 18001, Q: 1.4456, Reward pred: 1, Reward: -1, BF Gain pred: 79.90, BF Gain: 8.22, Critic Loss: 0.07, Policy Loss: -0.99\nBeam: 3, Iter: 18001, Q: 1.3651, Reward pred: -1, Reward: -1, BF Gain pred: 125.94, BF Gain: 42.59, Critic Loss: 0.12, Policy Loss: -0.97\nTraining for 500 iteration for each Beam uses 26.806751251220703 seconds.\nBeam: 0, Iter: 18501, Q: 1.2832, Reward pred: 1, Reward: -1, BF Gain pred: 188.62, BF Gain: 83.71, Critic Loss: 0.06, Policy Loss: -0.71\nBeam: 1, Iter: 18501, Q: 1.4313, Reward pred: 1, Reward: -1, BF Gain pred: 186.05, BF Gain: 61.81, Critic Loss: 0.06, Policy Loss: -1.09\nBeam: 2, Iter: 18501, Q: 1.5064, Reward pred: -1, Reward: -1, BF Gain pred: 92.21, BF Gain: 26.26, Critic Loss: 0.06, Policy Loss: -1.00\nBeam: 3, Iter: 18501, Q: 1.5706, Reward pred: 1, Reward: -1, BF Gain pred: 116.80, BF Gain: 24.13, Critic Loss: 0.08, Policy Loss: -0.88\nTraining for 500 iteration for each Beam uses 27.329667806625366 seconds.\nBeam: 0, Iter: 19001, Q: 1.4725, Reward pred: -1, Reward: -1, BF Gain pred: 203.39, BF Gain: 51.29, Critic Loss: 0.08, Policy Loss: -0.84\nBeam: 1, Iter: 19001, Q: 1.5294, Reward pred: 1, Reward: -1, BF Gain pred: 186.26, BF Gain: 28.08, Critic Loss: 0.05, Policy Loss: -1.05\nBeam: 2, Iter: 19001, Q: 1.9868, Reward pred: -1, Reward: -1, BF Gain pred: 85.27, BF Gain: 43.71, Critic Loss: 0.08, Policy Loss: -0.97\nBeam: 3, Iter: 19001, Q: 1.4416, Reward pred: -1, Reward: -1, BF Gain pred: 133.61, BF Gain: 36.03, Critic Loss: 0.07, Policy Loss: -1.09\nTraining for 500 iteration for each Beam uses 27.25491499900818 seconds.\nBeam: 0, Iter: 19501, Q: 1.5569, Reward pred: -1, Reward: -1, BF Gain pred: 188.06, BF Gain: 24.68, Critic Loss: 0.08, Policy Loss: -0.86\nBeam: 1, Iter: 19501, Q: 2.6510, Reward pred: -1, Reward: -1, BF Gain pred: 189.19, BF Gain: 114.89, Critic Loss: 0.06, Policy Loss: -1.11\nBeam: 2, Iter: 19501, Q: 1.4103, Reward pred: -1, Reward: -1, BF Gain pred: 89.96, BF Gain: 37.40, Critic Loss: 0.06, Policy Loss: -1.02\nBeam: 3, Iter: 19501, Q: 1.1956, Reward pred: 1, Reward: -1, BF Gain pred: 129.52, BF Gain: 25.84, Critic Loss: 0.21, Policy Loss: -0.68\nTraining for 500 iteration for each Beam uses 27.38101053237915 seconds.\nBeam: 0, Iter: 20001, Q: 0.6193, Reward pred: 1, Reward: -1, BF Gain pred: 217.58, BF Gain: 84.76, Critic Loss: 0.36, Policy Loss: -0.24\nBeam: 1, Iter: 20001, Q: 1.5367, Reward pred: 1, Reward: -1, BF Gain pred: 164.41, BF Gain: 37.73, Critic Loss: 0.05, Policy Loss: -1.08\nBeam: 2, Iter: 20001, Q: 1.4868, Reward pred: 1, Reward: -1, BF Gain pred: 88.91, BF Gain: 41.98, Critic Loss: 0.03, Policy Loss: -1.14\nBeam: 3, Iter: 20001, Q: 1.5113, Reward pred: -1, Reward: -1, BF Gain pred: 127.13, BF Gain: 48.93, Critic Loss: 0.08, Policy Loss: -0.86\nTraining for 500 iteration for each Beam uses 27.693830966949463 seconds.\nBeam: 0, Iter: 20501, Q: 2.7767, Reward pred: -1, Reward: -1, BF Gain pred: 193.36, BF Gain: 56.97, Critic Loss: 0.10, Policy Loss: -0.72\nBeam: 1, Iter: 20501, Q: 1.5594, Reward pred: -1, Reward: -1, BF Gain pred: 182.39, BF Gain: 45.52, Critic Loss: 0.05, Policy Loss: -1.01\nBeam: 2, Iter: 20501, Q: 1.6291, Reward pred: 1, Reward: -1, BF Gain pred: 95.23, BF Gain: 37.79, Critic Loss: 0.05, Policy Loss: -1.06\nBeam: 3, Iter: 20501, Q: 1.5446, Reward pred: -1, Reward: -1, BF Gain pred: 122.64, BF Gain: 23.34, Critic Loss: 0.06, Policy Loss: -1.08\nTraining for 500 iteration for each Beam uses 27.444868564605713 seconds.\nBeam: 0, Iter: 21001, Q: 1.8941, Reward pred: 1, Reward: -1, BF Gain pred: 187.00, BF Gain: 50.67, Critic Loss: 0.08, Policy Loss: -0.93\nBeam: 1, Iter: 21001, Q: 1.4987, Reward pred: 1, Reward: -1, BF Gain pred: 197.93, BF Gain: 99.90, Critic Loss: 0.08, Policy Loss: -0.90\nBeam: 2, Iter: 21001, Q: 1.6241, Reward pred: 1, Reward: -1, BF Gain pred: 87.15, BF Gain: 30.65, Critic Loss: 0.05, Policy Loss: -1.10\nBeam: 3, Iter: 21001, Q: 1.3923, Reward pred: 1, Reward: -1, BF Gain pred: 118.60, BF Gain: 68.67, Critic Loss: 0.07, Policy Loss: -0.89\nTraining for 500 iteration for each Beam uses 26.78634548187256 seconds.\nBeam: 0, Iter: 21501, Q: 1.3758, Reward pred: -1, Reward: -1, BF Gain pred: 193.61, BF Gain: 78.36, Critic Loss: 0.08, Policy Loss: -1.06\nBeam: 1, Iter: 21501, Q: 2.1557, Reward pred: 1, Reward: -1, BF Gain pred: 200.08, BF Gain: 102.58, Critic Loss: 0.09, Policy Loss: -1.00\nBeam: 2, Iter: 21501, Q: 1.3411, Reward pred: 1, Reward: -1, BF Gain pred: 86.26, BF Gain: 24.07, Critic Loss: 0.04, Policy Loss: -1.09\nBeam: 3, Iter: 21501, Q: 0.8500, Reward pred: -1, Reward: -1, BF Gain pred: 130.84, BF Gain: 52.13, Critic Loss: 0.23, Policy Loss: -0.55\nTraining for 500 iteration for each Beam uses 26.977890491485596 seconds.\nBeam: 0, Iter: 22001, Q: 1.5497, Reward pred: -1, Reward: -1, BF Gain pred: 164.68, BF Gain: 31.45, Critic Loss: 0.08, Policy Loss: -0.96\nBeam: 1, Iter: 22001, Q: 1.6407, Reward pred: 1, Reward: -1, BF Gain pred: 193.79, BF Gain: 22.11, Critic Loss: 0.06, Policy Loss: -0.97\nBeam: 2, Iter: 22001, Q: 1.4364, Reward pred: -1, Reward: -1, BF Gain pred: 95.77, BF Gain: 36.98, Critic Loss: 0.05, Policy Loss: -1.15\nBeam: 3, Iter: 22001, Q: 1.2357, Reward pred: -1, Reward: -1, BF Gain pred: 134.02, BF Gain: 50.35, Critic Loss: 0.11, Policy Loss: -0.89\nTraining for 500 iteration for each Beam uses 26.958521604537964 seconds.\nBeam: 0, Iter: 22501, Q: 0.2593, Reward pred: 1, Reward: -1, BF Gain pred: 204.79, BF Gain: 107.36, Critic Loss: 0.47, Policy Loss: -0.12\nBeam: 1, Iter: 22501, Q: 1.3803, Reward pred: 1, Reward: -1, BF Gain pred: 181.68, BF Gain: 91.06, Critic Loss: 0.05, Policy Loss: -1.04\nBeam: 2, Iter: 22501, Q: 1.3818, Reward pred: -1, Reward: -1, BF Gain pred: 83.68, BF Gain: 21.90, Critic Loss: 0.06, Policy Loss: -1.15\nBeam: 3, Iter: 22501, Q: 1.3284, Reward pred: -1, Reward: -1, BF Gain pred: 130.15, BF Gain: 46.68, Critic Loss: 0.09, Policy Loss: -0.94\nTraining for 500 iteration for each Beam uses 26.443296909332275 seconds.\nBeam: 0, Iter: 23001, Q: 1.2741, Reward pred: -1, Reward: -1, BF Gain pred: 196.14, BF Gain: 12.90, Critic Loss: 0.16, Policy Loss: -0.68\nBeam: 1, Iter: 23001, Q: 1.5543, Reward pred: -1, Reward: -1, BF Gain pred: 185.47, BF Gain: 74.99, Critic Loss: 0.07, Policy Loss: -1.07\nBeam: 2, Iter: 23001, Q: 1.5489, Reward pred: 1, Reward: -1, BF Gain pred: 82.72, BF Gain: 20.86, Critic Loss: 0.04, Policy Loss: -1.08\nBeam: 3, Iter: 23001, Q: 1.4468, Reward pred: 1, Reward: -1, BF Gain pred: 120.13, BF Gain: 67.48, Critic Loss: 0.07, Policy Loss: -1.00\nTraining for 500 iteration for each Beam uses 26.870747804641724 seconds.\nBeam: 0, Iter: 23501, Q: 1.7259, Reward pred: 1, Reward: -1, BF Gain pred: 200.68, BF Gain: 53.66, Critic Loss: 0.11, Policy Loss: -0.92\nBeam: 1, Iter: 23501, Q: 1.5231, Reward pred: -1, Reward: -1, BF Gain pred: 191.03, BF Gain: 101.05, Critic Loss: 0.06, Policy Loss: -1.08\nBeam: 2, Iter: 23501, Q: 1.8737, Reward pred: -1, Reward: -1, BF Gain pred: 88.60, BF Gain: 33.07, Critic Loss: 0.06, Policy Loss: -1.12\nBeam: 3, Iter: 23501, Q: 1.3602, Reward pred: 1, Reward: -1, BF Gain pred: 139.05, BF Gain: 53.12, Critic Loss: 0.05, Policy Loss: -0.92\nTraining for 500 iteration for each Beam uses 26.620007514953613 seconds.\nBeam: 0, Iter: 24001, Q: 1.6372, Reward pred: -1, Reward: -1, BF Gain pred: 207.63, BF Gain: 139.77, Critic Loss: 0.10, Policy Loss: -0.96\nBeam: 1, Iter: 24001, Q: 1.3257, Reward pred: -1, Reward: -1, BF Gain pred: 163.05, BF Gain: 46.98, Critic Loss: 0.07, Policy Loss: -0.97\nBeam: 2, Iter: 24001, Q: 1.3088, Reward pred: -1, Reward: -1, BF Gain pred: 86.75, BF Gain: 32.56, Critic Loss: 0.04, Policy Loss: -1.08\nBeam: 3, Iter: 24001, Q: 1.4464, Reward pred: 1, Reward: -1, BF Gain pred: 137.18, BF Gain: 69.09, Critic Loss: 0.06, Policy Loss: -1.08\nTraining for 500 iteration for each Beam uses 26.843726634979248 seconds.\nBeam: 0, Iter: 24501, Q: 1.3647, Reward pred: 1, Reward: -1, BF Gain pred: 197.74, BF Gain: 56.41, Critic Loss: 0.09, Policy Loss: -0.91\nBeam: 1, Iter: 24501, Q: 1.6892, Reward pred: -1, Reward: -1, BF Gain pred: 163.15, BF Gain: 64.02, Critic Loss: 0.05, Policy Loss: -1.08\nBeam: 2, Iter: 24501, Q: 1.6217, Reward pred: -1, Reward: -1, BF Gain pred: 89.27, BF Gain: 35.36, Critic Loss: 0.05, Policy Loss: -1.03\nBeam: 3, Iter: 24501, Q: 1.6915, Reward pred: 1, Reward: -1, BF Gain pred: 137.06, BF Gain: 38.39, Critic Loss: 0.06, Policy Loss: -1.07\nTraining for 500 iteration for each Beam uses 27.174410820007324 seconds.\nBeam: 0, Iter: 25001, Q: 1.6206, Reward pred: -1, Reward: -1, BF Gain pred: 208.81, BF Gain: 104.27, Critic Loss: 0.13, Policy Loss: -0.71\nBeam: 1, Iter: 25001, Q: 1.4351, Reward pred: 1, Reward: -1, BF Gain pred: 194.79, BF Gain: 71.44, Critic Loss: 0.05, Policy Loss: -1.02\nBeam: 2, Iter: 25001, Q: 1.3894, Reward pred: 1, Reward: -1, BF Gain pred: 97.00, BF Gain: 28.47, Critic Loss: 0.04, Policy Loss: -1.08\nBeam: 3, Iter: 25001, Q: 1.3209, Reward pred: 1, Reward: -1, BF Gain pred: 140.79, BF Gain: 54.45, Critic Loss: 0.07, Policy Loss: -1.02\nTraining for 500 iteration for each Beam uses 27.121550798416138 seconds.\nBeam: 0, Iter: 25501, Q: 1.5772, Reward pred: -1, Reward: -1, BF Gain pred: 215.21, BF Gain: 96.32, Critic Loss: 0.08, Policy Loss: -0.94\nBeam: 1, Iter: 25501, Q: 1.4793, Reward pred: -1, Reward: -1, BF Gain pred: 198.71, BF Gain: 61.87, Critic Loss: 0.07, Policy Loss: -1.06\nBeam: 2, Iter: 25501, Q: 1.4719, Reward pred: 1, Reward: -1, BF Gain pred: 94.06, BF Gain: 31.86, Critic Loss: 0.06, Policy Loss: -1.02\nBeam: 3, Iter: 25501, Q: 1.5029, Reward pred: 1, Reward: -1, BF Gain pred: 138.94, BF Gain: 45.79, Critic Loss: 0.08, Policy Loss: -1.17\nTraining for 500 iteration for each Beam uses 26.963281869888306 seconds.\nBeam: 0, Iter: 26001, Q: 1.2678, Reward pred: -1, Reward: -1, BF Gain pred: 218.09, BF Gain: 85.21, Critic Loss: 0.08, Policy Loss: -0.94\nBeam: 1, Iter: 26001, Q: 1.4276, Reward pred: 1, Reward: -1, BF Gain pred: 184.24, BF Gain: 85.78, Critic Loss: 0.06, Policy Loss: -1.02\nBeam: 2, Iter: 26001, Q: 2.2395, Reward pred: -1, Reward: -1, BF Gain pred: 86.47, BF Gain: 30.55, Critic Loss: 0.06, Policy Loss: -1.05\nBeam: 3, Iter: 26001, Q: 1.5447, Reward pred: -1, Reward: -1, BF Gain pred: 143.08, BF Gain: 57.49, Critic Loss: 0.05, Policy Loss: -1.06\nTraining for 500 iteration for each Beam uses 27.31057095527649 seconds.\nBeam: 0, Iter: 26501, Q: 1.5840, Reward pred: 1, Reward: -1, BF Gain pred: 217.35, BF Gain: 70.33, Critic Loss: 0.08, Policy Loss: -0.87\nBeam: 1, Iter: 26501, Q: 1.7971, Reward pred: 1, Reward: -1, BF Gain pred: 191.70, BF Gain: 47.99, Critic Loss: 0.09, Policy Loss: -1.05\nBeam: 2, Iter: 26501, Q: 1.5349, Reward pred: 1, Reward: -1, BF Gain pred: 99.87, BF Gain: 45.61, Critic Loss: 0.05, Policy Loss: -1.03\nBeam: 3, Iter: 26501, Q: 1.4739, Reward pred: -1, Reward: -1, BF Gain pred: 142.63, BF Gain: 58.65, Critic Loss: 0.06, Policy Loss: -1.05\nTraining for 500 iteration for each Beam uses 26.88182044029236 seconds.\nBeam: 0, Iter: 27001, Q: 1.4497, Reward pred: 1, Reward: -1, BF Gain pred: 218.60, BF Gain: 103.76, Critic Loss: 0.06, Policy Loss: -0.95\nBeam: 1, Iter: 27001, Q: 1.5180, Reward pred: -1, Reward: -1, BF Gain pred: 188.15, BF Gain: 69.74, Critic Loss: 0.07, Policy Loss: -1.03\nBeam: 2, Iter: 27001, Q: 1.2695, Reward pred: -1, Reward: -1, BF Gain pred: 82.97, BF Gain: 42.22, Critic Loss: 0.06, Policy Loss: -1.03\nBeam: 3, Iter: 27001, Q: 1.4183, Reward pred: -1, Reward: -1, BF Gain pred: 127.06, BF Gain: 51.40, Critic Loss: 0.06, Policy Loss: -1.01\nTraining for 500 iteration for each Beam uses 26.630677938461304 seconds.\nBeam: 0, Iter: 27501, Q: 1.7636, Reward pred: -1, Reward: -1, BF Gain pred: 217.39, BF Gain: 108.00, Critic Loss: 0.09, Policy Loss: -0.95\nBeam: 1, Iter: 27501, Q: 1.4819, Reward pred: -1, Reward: -1, BF Gain pred: 192.69, BF Gain: 138.07, Critic Loss: 0.07, Policy Loss: -1.02\nBeam: 2, Iter: 27501, Q: 1.5147, Reward pred: 1, Reward: -1, BF Gain pred: 97.24, BF Gain: 37.75, Critic Loss: 0.06, Policy Loss: -1.09\nBeam: 3, Iter: 27501, Q: 1.5034, Reward pred: 1, Reward: -1, BF Gain pred: 145.34, BF Gain: 62.02, Critic Loss: 0.06, Policy Loss: -1.10\nTraining for 500 iteration for each Beam uses 26.751084327697754 seconds.\nBeam: 0, Iter: 28001, Q: 1.4140, Reward pred: 1, Reward: -1, BF Gain pred: 213.30, BF Gain: 48.47, Critic Loss: 0.07, Policy Loss: -0.95\nBeam: 1, Iter: 28001, Q: 1.4860, Reward pred: -1, Reward: -1, BF Gain pred: 191.73, BF Gain: 62.74, Critic Loss: 0.06, Policy Loss: -1.16\nBeam: 2, Iter: 28001, Q: 1.6763, Reward pred: 1, Reward: -1, BF Gain pred: 94.01, BF Gain: 33.38, Critic Loss: 0.04, Policy Loss: -0.97\nBeam: 3, Iter: 28001, Q: 1.8431, Reward pred: 1, Reward: -1, BF Gain pred: 145.40, BF Gain: 81.61, Critic Loss: 0.05, Policy Loss: -1.06\nTraining for 500 iteration for each Beam uses 26.874822854995728 seconds.\nBeam: 0, Iter: 28501, Q: 2.1809, Reward pred: -1, Reward: -1, BF Gain pred: 213.42, BF Gain: 94.24, Critic Loss: 0.49, Policy Loss: -0.37\nBeam: 1, Iter: 28501, Q: 1.5974, Reward pred: -1, Reward: -1, BF Gain pred: 185.93, BF Gain: 92.35, Critic Loss: 0.06, Policy Loss: -1.04\nBeam: 2, Iter: 28501, Q: 1.4294, Reward pred: 1, Reward: -1, BF Gain pred: 100.55, BF Gain: 23.82, Critic Loss: 0.05, Policy Loss: -0.98\nBeam: 3, Iter: 28501, Q: 1.5279, Reward pred: -1, Reward: -1, BF Gain pred: 141.36, BF Gain: 66.00, Critic Loss: 0.04, Policy Loss: -1.03\nTraining for 500 iteration for each Beam uses 26.858434200286865 seconds.\nBeam: 0, Iter: 29001, Q: 1.4524, Reward pred: 1, Reward: -1, BF Gain pred: 222.17, BF Gain: 63.60, Critic Loss: 0.07, Policy Loss: -0.98\nBeam: 1, Iter: 29001, Q: 1.4648, Reward pred: -1, Reward: -1, BF Gain pred: 188.91, BF Gain: 87.49, Critic Loss: 0.07, Policy Loss: -1.11\nBeam: 2, Iter: 29001, Q: 1.4576, Reward pred: -1, Reward: -1, BF Gain pred: 94.94, BF Gain: 43.49, Critic Loss: 0.04, Policy Loss: -1.02\nBeam: 3, Iter: 29001, Q: 2.7258, Reward pred: 1, Reward: -1, BF Gain pred: 145.89, BF Gain: 32.83, Critic Loss: 0.06, Policy Loss: -1.02\nTraining for 500 iteration for each Beam uses 26.965795278549194 seconds.\nBeam: 0, Iter: 29501, Q: 1.3572, Reward pred: -1, Reward: -1, BF Gain pred: 210.47, BF Gain: 63.59, Critic Loss: 0.07, Policy Loss: -0.85\nBeam: 1, Iter: 29501, Q: 1.4690, Reward pred: 1, Reward: -1, BF Gain pred: 189.52, BF Gain: 77.52, Critic Loss: 0.06, Policy Loss: -1.03\nBeam: 2, Iter: 29501, Q: 1.6677, Reward pred: 1, Reward: -1, BF Gain pred: 94.14, BF Gain: 21.11, Critic Loss: 0.06, Policy Loss: -0.94\nBeam: 3, Iter: 29501, Q: 1.3972, Reward pred: 1, Reward: -1, BF Gain pred: 134.18, BF Gain: 49.97, Critic Loss: 0.04, Policy Loss: -1.12\nTraining for 500 iteration for each Beam uses 26.76829695701599 seconds.\nBeam: 0, Iter: 30001, Q: 1.4848, Reward pred: -1, Reward: -1, BF Gain pred: 207.47, BF Gain: 54.17, Critic Loss: 0.07, Policy Loss: -0.93\nBeam: 1, Iter: 30001, Q: 1.3516, Reward pred: 1, Reward: -1, BF Gain pred: 214.21, BF Gain: 76.78, Critic Loss: 0.08, Policy Loss: -0.97\nBeam: 2, Iter: 30001, Q: 1.5597, Reward pred: -1, Reward: -1, BF Gain pred: 97.75, BF Gain: 43.54, Critic Loss: 0.06, Policy Loss: -1.03\nBeam: 3, Iter: 30001, Q: 2.2308, Reward pred: 1, Reward: -1, BF Gain pred: 144.77, BF Gain: 66.41, Critic Loss: 0.05, Policy Loss: -1.07\nTraining for 500 iteration for each Beam uses 26.87174415588379 seconds.\nBeam: 0, Iter: 30501, Q: 1.8663, Reward pred: -1, Reward: -1, BF Gain pred: 228.38, BF Gain: 59.58, Critic Loss: 0.08, Policy Loss: -1.02\nBeam: 1, Iter: 30501, Q: 1.5885, Reward pred: -1, Reward: -1, BF Gain pred: 153.32, BF Gain: 74.56, Critic Loss: 0.06, Policy Loss: -1.02\nBeam: 2, Iter: 30501, Q: 1.6725, Reward pred: 1, Reward: -1, BF Gain pred: 100.79, BF Gain: 21.43, Critic Loss: 0.05, Policy Loss: -1.08\nBeam: 3, Iter: 30501, Q: 1.4269, Reward pred: -1, Reward: -1, BF Gain pred: 117.06, BF Gain: 41.30, Critic Loss: 0.05, Policy Loss: -1.06\nTraining for 500 iteration for each Beam uses 26.798834562301636 seconds.\nBeam: 0, Iter: 31001, Q: 1.3814, Reward pred: 1, Reward: -1, BF Gain pred: 210.79, BF Gain: 50.70, Critic Loss: 0.06, Policy Loss: -0.97\nBeam: 1, Iter: 31001, Q: 1.5391, Reward pred: 1, Reward: -1, BF Gain pred: 200.00, BF Gain: 90.35, Critic Loss: 0.07, Policy Loss: -1.03\nBeam: 2, Iter: 31001, Q: 1.6054, Reward pred: 1, Reward: -1, BF Gain pred: 99.63, BF Gain: 29.53, Critic Loss: 0.06, Policy Loss: -1.07\nBeam: 3, Iter: 31001, Q: 1.5208, Reward pred: 1, Reward: -1, BF Gain pred: 136.07, BF Gain: 44.65, Critic Loss: 0.06, Policy Loss: -1.03\nTraining for 500 iteration for each Beam uses 26.906631231307983 seconds.\nBeam: 0, Iter: 31501, Q: 1.4226, Reward pred: 1, Reward: -1, BF Gain pred: 218.37, BF Gain: 74.44, Critic Loss: 0.07, Policy Loss: -0.95\nBeam: 1, Iter: 31501, Q: 1.7553, Reward pred: -1, Reward: -1, BF Gain pred: 177.80, BF Gain: 77.31, Critic Loss: 0.07, Policy Loss: -1.02\nBeam: 2, Iter: 31501, Q: 1.4044, Reward pred: 1, Reward: -1, BF Gain pred: 91.67, BF Gain: 16.25, Critic Loss: 0.06, Policy Loss: -1.12\nBeam: 3, Iter: 31501, Q: 1.4577, Reward pred: -1, Reward: -1, BF Gain pred: 137.50, BF Gain: 29.64, Critic Loss: 0.06, Policy Loss: -1.10\nTraining for 500 iteration for each Beam uses 26.83643078804016 seconds.\nBeam: 0, Iter: 32001, Q: 1.6624, Reward pred: -1, Reward: -1, BF Gain pred: 205.91, BF Gain: 84.87, Critic Loss: 0.08, Policy Loss: -0.91\nBeam: 1, Iter: 32001, Q: 1.3755, Reward pred: 1, Reward: -1, BF Gain pred: 202.37, BF Gain: 112.29, Critic Loss: 0.06, Policy Loss: -1.18\nBeam: 2, Iter: 32001, Q: 1.3818, Reward pred: -1, Reward: -1, BF Gain pred: 91.18, BF Gain: 33.59, Critic Loss: 0.05, Policy Loss: -1.09\nBeam: 3, Iter: 32001, Q: 1.4736, Reward pred: 1, Reward: -1, BF Gain pred: 139.21, BF Gain: 66.78, Critic Loss: 0.07, Policy Loss: -1.06\nTraining for 500 iteration for each Beam uses 26.848201513290405 seconds.\nBeam: 0, Iter: 32501, Q: 1.6073, Reward pred: -1, Reward: -1, BF Gain pred: 222.06, BF Gain: 103.88, Critic Loss: 0.06, Policy Loss: -1.04\nBeam: 1, Iter: 32501, Q: 1.6835, Reward pred: 1, Reward: -1, BF Gain pred: 205.84, BF Gain: 82.79, Critic Loss: 0.05, Policy Loss: -1.13\nBeam: 2, Iter: 32501, Q: 1.4753, Reward pred: -1, Reward: -1, BF Gain pred: 85.54, BF Gain: 50.80, Critic Loss: 0.05, Policy Loss: -1.11\nBeam: 3, Iter: 32501, Q: 1.4481, Reward pred: 1, Reward: -1, BF Gain pred: 136.59, BF Gain: 39.91, Critic Loss: 0.06, Policy Loss: -1.03\nTraining for 500 iteration for each Beam uses 27.3615825176239 seconds.\nBeam: 0, Iter: 33001, Q: 1.6247, Reward pred: -1, Reward: -1, BF Gain pred: 205.39, BF Gain: 82.03, Critic Loss: 0.06, Policy Loss: -0.98\nBeam: 1, Iter: 33001, Q: 1.8425, Reward pred: 1, Reward: -1, BF Gain pred: 214.47, BF Gain: 75.76, Critic Loss: 0.06, Policy Loss: -1.13\nBeam: 2, Iter: 33001, Q: 1.4826, Reward pred: 1, Reward: -1, BF Gain pred: 94.69, BF Gain: 39.95, Critic Loss: 0.06, Policy Loss: -1.04\nBeam: 3, Iter: 33001, Q: 1.7759, Reward pred: -1, Reward: -1, BF Gain pred: 138.30, BF Gain: 39.30, Critic Loss: 0.06, Policy Loss: -1.08\nTraining for 500 iteration for each Beam uses 26.939042806625366 seconds.\nBeam: 0, Iter: 33501, Q: 2.3487, Reward pred: 1, Reward: -1, BF Gain pred: 226.28, BF Gain: 116.52, Critic Loss: 0.08, Policy Loss: -0.98\nBeam: 1, Iter: 33501, Q: 1.6500, Reward pred: -1, Reward: -1, BF Gain pred: 189.41, BF Gain: 99.64, Critic Loss: 0.06, Policy Loss: -1.12\nBeam: 2, Iter: 33501, Q: 1.3795, Reward pred: 1, Reward: -1, BF Gain pred: 87.30, BF Gain: 19.68, Critic Loss: 0.06, Policy Loss: -1.08\nBeam: 3, Iter: 33501, Q: 1.3657, Reward pred: -1, Reward: -1, BF Gain pred: 138.27, BF Gain: 86.38, Critic Loss: 0.05, Policy Loss: -1.17\nTraining for 500 iteration for each Beam uses 26.858610153198242 seconds.\nBeam: 0, Iter: 34001, Q: 1.6412, Reward pred: 1, Reward: -1, BF Gain pred: 210.79, BF Gain: 116.81, Critic Loss: 0.08, Policy Loss: -0.95\nBeam: 1, Iter: 34001, Q: 1.5300, Reward pred: 1, Reward: -1, BF Gain pred: 204.86, BF Gain: 123.34, Critic Loss: 0.08, Policy Loss: -1.13\nBeam: 2, Iter: 34001, Q: 1.5934, Reward pred: -1, Reward: -1, BF Gain pred: 100.21, BF Gain: 38.24, Critic Loss: 0.05, Policy Loss: -1.14\nBeam: 3, Iter: 34001, Q: 1.4761, Reward pred: -1, Reward: -1, BF Gain pred: 127.91, BF Gain: 60.48, Critic Loss: 0.05, Policy Loss: -1.12\nTraining for 500 iteration for each Beam uses 26.932368278503418 seconds.\nBeam: 0, Iter: 34501, Q: 1.3641, Reward pred: 1, Reward: -1, BF Gain pred: 220.19, BF Gain: 125.54, Critic Loss: 0.08, Policy Loss: -1.01\nBeam: 1, Iter: 34501, Q: 1.5767, Reward pred: -1, Reward: -1, BF Gain pred: 188.18, BF Gain: 77.24, Critic Loss: 0.05, Policy Loss: -1.24\nBeam: 2, Iter: 34501, Q: 1.5282, Reward pred: -1, Reward: -1, BF Gain pred: 98.79, BF Gain: 39.79, Critic Loss: 0.06, Policy Loss: -0.99\nBeam: 3, Iter: 34501, Q: 1.3531, Reward pred: 1, Reward: -1, BF Gain pred: 121.95, BF Gain: 53.69, Critic Loss: 0.06, Policy Loss: -1.12\nTraining for 500 iteration for each Beam uses 27.185378789901733 seconds.\nBeam: 0, Iter: 35001, Q: 1.4804, Reward pred: 1, Reward: -1, BF Gain pred: 220.79, BF Gain: 104.67, Critic Loss: 0.08, Policy Loss: -1.11\nBeam: 1, Iter: 35001, Q: 2.2371, Reward pred: 1, Reward: -1, BF Gain pred: 203.65, BF Gain: 105.57, Critic Loss: 0.05, Policy Loss: -1.16\nBeam: 2, Iter: 35001, Q: 1.4515, Reward pred: 1, Reward: -1, BF Gain pred: 95.50, BF Gain: 33.30, Critic Loss: 0.05, Policy Loss: -1.08\nBeam: 3, Iter: 35001, Q: 1.5490, Reward pred: 1, Reward: -1, BF Gain pred: 138.01, BF Gain: 60.55, Critic Loss: 0.06, Policy Loss: -1.23\nTraining for 500 iteration for each Beam uses 26.95772624015808 seconds.\nBeam: 0, Iter: 35501, Q: 1.5753, Reward pred: -1, Reward: -1, BF Gain pred: 199.89, BF Gain: 97.48, Critic Loss: 0.08, Policy Loss: -0.95\nBeam: 1, Iter: 35501, Q: 1.7196, Reward pred: -1, Reward: -1, BF Gain pred: 197.71, BF Gain: 92.92, Critic Loss: 0.07, Policy Loss: -1.15\nBeam: 2, Iter: 35501, Q: 1.4615, Reward pred: -1, Reward: -1, BF Gain pred: 92.86, BF Gain: 49.45, Critic Loss: 0.05, Policy Loss: -1.04\nBeam: 3, Iter: 35501, Q: 1.4243, Reward pred: -1, Reward: -1, BF Gain pred: 145.23, BF Gain: 72.46, Critic Loss: 0.05, Policy Loss: -1.21\nTraining for 500 iteration for each Beam uses 26.931464195251465 seconds.\nBeam: 0, Iter: 36001, Q: 1.4429, Reward pred: 1, Reward: -1, BF Gain pred: 219.28, BF Gain: 137.17, Critic Loss: 0.07, Policy Loss: -1.05\nBeam: 1, Iter: 36001, Q: 1.5767, Reward pred: 1, Reward: -1, BF Gain pred: 188.72, BF Gain: 99.39, Critic Loss: 0.06, Policy Loss: -1.26\nBeam: 2, Iter: 36001, Q: 1.4436, Reward pred: -1, Reward: -1, BF Gain pred: 95.17, BF Gain: 36.99, Critic Loss: 0.06, Policy Loss: -1.04\nBeam: 3, Iter: 36001, Q: 1.6188, Reward pred: 1, Reward: -1, BF Gain pred: 147.90, BF Gain: 63.51, Critic Loss: 0.06, Policy Loss: -1.12\nTraining for 500 iteration for each Beam uses 26.95259189605713 seconds.\nBeam: 0, Iter: 36501, Q: 1.7137, Reward pred: 1, Reward: -1, BF Gain pred: 207.88, BF Gain: 86.51, Critic Loss: 0.07, Policy Loss: -1.10\nBeam: 1, Iter: 36501, Q: 1.5225, Reward pred: 1, Reward: -1, BF Gain pred: 187.55, BF Gain: 92.14, Critic Loss: 0.07, Policy Loss: -1.24\nBeam: 2, Iter: 36501, Q: 1.7607, Reward pred: -1, Reward: -1, BF Gain pred: 98.56, BF Gain: 41.14, Critic Loss: 0.07, Policy Loss: -1.02\nBeam: 3, Iter: 36501, Q: 1.2937, Reward pred: 1, Reward: -1, BF Gain pred: 150.36, BF Gain: 46.83, Critic Loss: 0.07, Policy Loss: -1.11\nTraining for 500 iteration for each Beam uses 27.126288414001465 seconds.\nBeam: 0, Iter: 37001, Q: 1.6975, Reward pred: -1, Reward: -1, BF Gain pred: 214.99, BF Gain: 109.71, Critic Loss: 0.08, Policy Loss: -1.01\nBeam: 1, Iter: 37001, Q: 1.7658, Reward pred: 1, Reward: -1, BF Gain pred: 208.19, BF Gain: 95.40, Critic Loss: 0.04, Policy Loss: -1.23\nBeam: 2, Iter: 37001, Q: 1.3874, Reward pred: 1, Reward: -1, BF Gain pred: 96.66, BF Gain: 45.08, Critic Loss: 0.06, Policy Loss: -1.09\nBeam: 3, Iter: 37001, Q: 1.4231, Reward pred: -1, Reward: -1, BF Gain pred: 128.83, BF Gain: 73.07, Critic Loss: 0.08, Policy Loss: -1.20\nTraining for 500 iteration for each Beam uses 27.137707948684692 seconds.\nBeam: 0, Iter: 37501, Q: 1.8026, Reward pred: -1, Reward: -1, BF Gain pred: 219.58, BF Gain: 48.31, Critic Loss: 0.06, Policy Loss: -1.11\nBeam: 1, Iter: 37501, Q: 1.4524, Reward pred: -1, Reward: -1, BF Gain pred: 198.66, BF Gain: 140.85, Critic Loss: 0.06, Policy Loss: -1.27\nBeam: 2, Iter: 37501, Q: 1.4017, Reward pred: 1, Reward: -1, BF Gain pred: 74.54, BF Gain: 32.06, Critic Loss: 0.05, Policy Loss: -1.16\nBeam: 3, Iter: 37501, Q: 1.4678, Reward pred: -1, Reward: -1, BF Gain pred: 144.11, BF Gain: 46.46, Critic Loss: 0.07, Policy Loss: -1.14\nTraining for 500 iteration for each Beam uses 27.070384740829468 seconds.\nBeam: 0, Iter: 38001, Q: 1.7524, Reward pred: 1, Reward: -1, BF Gain pred: 214.54, BF Gain: 124.99, Critic Loss: 0.08, Policy Loss: -1.10\nBeam: 1, Iter: 38001, Q: 1.5188, Reward pred: -1, Reward: -1, BF Gain pred: 179.55, BF Gain: 107.63, Critic Loss: 0.06, Policy Loss: -1.13\nBeam: 2, Iter: 38001, Q: 1.3739, Reward pred: -1, Reward: -1, BF Gain pred: 99.78, BF Gain: 36.69, Critic Loss: 0.06, Policy Loss: -1.10\nBeam: 3, Iter: 38001, Q: 1.4598, Reward pred: -1, Reward: -1, BF Gain pred: 138.01, BF Gain: 41.76, Critic Loss: 0.06, Policy Loss: -1.29\nTraining for 500 iteration for each Beam uses 27.083082675933838 seconds.\nBeam: 0, Iter: 38501, Q: 1.5468, Reward pred: 1, Reward: -1, BF Gain pred: 234.40, BF Gain: 112.58, Critic Loss: 0.09, Policy Loss: -0.97\nBeam: 1, Iter: 38501, Q: 1.6835, Reward pred: -1, Reward: -1, BF Gain pred: 206.56, BF Gain: 135.19, Critic Loss: 0.07, Policy Loss: -1.21\nBeam: 2, Iter: 38501, Q: 2.2823, Reward pred: -1, Reward: -1, BF Gain pred: 94.24, BF Gain: 39.38, Critic Loss: 0.07, Policy Loss: -1.15\nBeam: 3, Iter: 38501, Q: 1.6675, Reward pred: 1, Reward: -1, BF Gain pred: 148.70, BF Gain: 70.55, Critic Loss: 0.07, Policy Loss: -1.21\nTraining for 500 iteration for each Beam uses 27.189172744750977 seconds.\nBeam: 0, Iter: 39001, Q: 1.5157, Reward pred: 1, Reward: -1, BF Gain pred: 220.54, BF Gain: 91.79, Critic Loss: 0.07, Policy Loss: -0.93\nBeam: 1, Iter: 39001, Q: 1.4601, Reward pred: -1, Reward: -1, BF Gain pred: 167.06, BF Gain: 97.37, Critic Loss: 0.06, Policy Loss: -1.24\nBeam: 2, Iter: 39001, Q: 1.7959, Reward pred: 1, Reward: -1, BF Gain pred: 100.99, BF Gain: 47.27, Critic Loss: 0.07, Policy Loss: -1.12\nBeam: 3, Iter: 39001, Q: 1.4899, Reward pred: -1, Reward: -1, BF Gain pred: 107.24, BF Gain: 47.61, Critic Loss: 0.06, Policy Loss: -1.13\nTraining for 500 iteration for each Beam uses 27.16324520111084 seconds.\nBeam: 0, Iter: 39501, Q: 1.5711, Reward pred: 1, Reward: -1, BF Gain pred: 225.86, BF Gain: 101.88, Critic Loss: 0.08, Policy Loss: -1.02\nBeam: 1, Iter: 39501, Q: 1.6601, Reward pred: -1, Reward: -1, BF Gain pred: 186.82, BF Gain: 88.55, Critic Loss: 0.06, Policy Loss: -1.28\nBeam: 2, Iter: 39501, Q: 1.4015, Reward pred: 1, Reward: -1, BF Gain pred: 95.67, BF Gain: 43.59, Critic Loss: 0.05, Policy Loss: -1.01\nBeam: 3, Iter: 39501, Q: 1.4516, Reward pred: 1, Reward: -1, BF Gain pred: 138.49, BF Gain: 65.08, Critic Loss: 0.06, Policy Loss: -1.22\nTraining for 500 iteration for each Beam uses 27.20342469215393 seconds.\nBeam: 0, Iter: 40001, Q: 1.6029, Reward pred: 1, Reward: -1, BF Gain pred: 221.44, BF Gain: 70.18, Critic Loss: 0.08, Policy Loss: -1.00\nBeam: 1, Iter: 40001, Q: 1.5454, Reward pred: -1, Reward: -1, BF Gain pred: 207.39, BF Gain: 120.35, Critic Loss: 0.06, Policy Loss: -1.27\nBeam: 2, Iter: 40001, Q: 1.4272, Reward pred: -1, Reward: -1, BF Gain pred: 97.76, BF Gain: 45.79, Critic Loss: 0.05, Policy Loss: -1.14\nBeam: 3, Iter: 40001, Q: 1.7482, Reward pred: -1, Reward: -1, BF Gain pred: 140.95, BF Gain: 45.65, Critic Loss: 0.08, Policy Loss: -1.27\nTraining for 500 iteration for each Beam uses 27.358012676239014 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport scipy.io as scio\n\nnum_ant = 32\nnum_beam = 4\nresults = np.empty((num_beam, 2*num_ant))\n\npath = './beams/'\n\nfor beam_id in range(num_beam):\n    fname = 'beams_' + str(beam_id) + '_max.txt'\n    with open(path + fname, 'r') as f:\n        lines = f.readlines()\n        last_line = lines[-1]\n        results[beam_id, :] = np.fromstring(last_line.replace(\"\\n\", \"\"), sep=',').reshape(1, -1)\n\nresults = (1 / np.sqrt(num_ant)) * (results[:, ::2] + 1j * results[:, 1::2])\n\nscio.savemat('beam_codebook.mat', {'beams': results})","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:47:10.239328Z","iopub.execute_input":"2023-11-06T19:47:10.239597Z","iopub.status.idle":"2023-11-06T19:47:10.249306Z","shell.execute_reply.started":"2023-11-06T19:47:10.239575Z","shell.execute_reply":"2023-11-06T19:47:10.248447Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.figure(figsize=(12, 8))\nplt.title(f'Best beamforming gain')\nplt.xlabel('Beam_framing_gain')   \nfor beam_id in range(options['num_NNs']):\n    gain_record=np.array(env_list[beam_id].gain_history[1:])\n    np.save(f'beam_{beam_id}_gain_records',gain_record)\n    plt.plot(gain_record, label=f'Beam_{beam_id}')\n    plt.plot([])\nplt.plot([231.17094]*40000,linestyle='dashed',color='black')\nplt.legend(loc=\"lower right\")  \nplt.show()    ","metadata":{"execution":{"iopub.status.busy":"2023-11-06T19:47:10.251666Z","iopub.execute_input":"2023-11-06T19:47:10.251983Z","iopub.status.idle":"2023-11-06T19:47:10.691829Z","shell.execute_reply.started":"2023-11-06T19:47:10.251958Z","shell.execute_reply":"2023-11-06T19:47:10.690894Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x800 with 1 Axes>","image/png":"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"},"metadata":{}}]}]}