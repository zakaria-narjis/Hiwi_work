{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/YuZhang-GitHub/Codebook_Learning_RL.git","metadata":{"execution":{"iopub.status.busy":"2023-10-06T09:23:18.050453Z","iopub.execute_input":"2023-10-06T09:23:18.050939Z","iopub.status.idle":"2023-10-06T09:23:19.264520Z","shell.execute_reply.started":"2023-10-06T09:23:18.050884Z","shell.execute_reply":"2023-10-06T09:23:19.263149Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"fatal: destination path 'Codebook_Learning_RL' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.chdir('/kaggle/working/Codebook_Learning_RL')\nprint(os.getcwd())","metadata":{"execution":{"iopub.status.busy":"2023-10-06T09:23:19.267103Z","iopub.execute_input":"2023-10-06T09:23:19.268551Z","iopub.status.idle":"2023-10-06T09:23:19.276105Z","shell.execute_reply.started":"2023-10-06T09:23:19.268507Z","shell.execute_reply":"2023-10-06T09:23:19.274736Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/working/Codebook_Learning_RL\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport numpy as np\nimport copy\nimport pickle\nfrom scipy.optimize import linear_sum_assignment\nfrom DataPrep import dataPrep\nfrom env_ddpg import envCB\nfrom clustering import KMeans_only\nfrom function_lib import bf_gain_cal, corr_mining\nfrom DDPG_classes import Actor, Critic, OUNoise, init_weights","metadata":{"execution":{"iopub.status.busy":"2023-10-06T09:23:19.277796Z","iopub.execute_input":"2023-10-06T09:23:19.278589Z","iopub.status.idle":"2023-10-06T09:23:21.312226Z","shell.execute_reply.started":"2023-10-06T09:23:19.278552Z","shell.execute_reply":"2023-10-06T09:23:21.311094Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"options = {\n        'gpu_idx': 0,\n        'num_ant': 32,\n        'num_bits': 4,\n        'num_NNs': 4,  # codebook size\n        'ch_sample_ratio': 0.5,\n        'num_loop': 400,  # outer loop\n        'target_update': 3,\n        'path': './grid1101-1400.mat',\n        'clustering_mode': 'random',\n    }\n\ntrain_opt = {\n        'state': 0,\n        'best_state': 0,\n        'num_iter': 100,  # inner loop\n        'tau': 1e-2,\n        'overall_iter': 1,\n        'replay_memory': [],\n        'replay_memory_size': 8192,\n        'minibatch_size': 1024,\n        'gamma': 0\n    }\nif not os.path.exists('beams/'):\n    os.mkdir('beams/')\n\nch = dataPrep(options['path'])\nch = np.concatenate((ch[:, :options['num_ant']],\n                     ch[:, int(ch.shape[1] / 2):int(ch.shape[1] / 2) + options['num_ant']]), axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-06T09:23:21.314971Z","iopub.execute_input":"2023-10-06T09:23:21.315827Z","iopub.status.idle":"2023-10-06T09:23:22.482159Z","shell.execute_reply.started":"2023-10-06T09:23:21.315787Z","shell.execute_reply":"2023-10-06T09:23:22.481005Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ndef train(actor_net,\n          critic_net,\n          actor_net_t,\n          critic_net_t,\n          ounoise,\n          env,\n          options,\n          train_options,\n          beam_id):\n    CB_Env = env\n    critic_optimizer = optim.Adam(critic_net.parameters(), lr=1e-3, weight_decay=1e-3)\n    actor_optimizer = optim.Adam(actor_net.parameters(), lr=1e-3, weight_decay=1e-2)\n    critic_criterion = nn.MSELoss()\n\n    if train_options['overall_iter'] == 1:\n        state = torch.zeros((1, options['num_ant'])).float().cuda()\n        print('Initial State Activated.')\n    else:\n        state = train_options['state']\n\n    # -------------- Training -------------- #\n    replay_memory = train_options['replay_memory']\n    iteration = 0\n    num_of_iter = train_options['num_iter']\n    while iteration < num_of_iter:\n\n        # Proto-action\n        action_pred = actor_net(state)\n        reward_pred, bf_gain_pred, action_quant_pred, state_1_pred = CB_Env.get_reward(action_pred)\n        reward_pred = torch.from_numpy(reward_pred).float().cuda()\n\n        # Exploration and Quantization Processing\n        action_pred_noisy = ounoise.get_action(action_pred,\n                                               t=train_options['overall_iter'])  # torch.Size([1, action_dim])\n        mat_dist = torch.abs(action_pred_noisy.reshape(options['num_ant'], 1) - options['ph_table_rep'])\n        action_quant = options['ph_table_rep'][range(options['num_ant']), torch.argmin(mat_dist, dim=1)].reshape(1, -1)\n\n        state_1, reward, bf_gain, terminal = CB_Env.step(action_quant)\n        reward = torch.from_numpy(reward).float().cuda()\n        action = action_quant.reshape((1, -1)).float().cuda()\n\n        replay_memory.append((state, action, reward, state_1, terminal))\n        replay_memory.append((state, action_quant_pred, reward_pred, state_1_pred, terminal))\n        while len(replay_memory) > train_options['replay_memory_size']:\n            replay_memory.pop(0)\n\n        # -------------- Experience Replay -------------- #\n        minibatch = random.sample(replay_memory, min(len(replay_memory), train_options['minibatch_size']))\n\n        state_batch = torch.cat(tuple(d[0] for d in minibatch))  # torch.Size([*, state_dim])\n        action_batch = torch.cat(tuple(d[1] for d in minibatch))  # torch.Size([*, action_dim])\n        reward_batch = torch.cat(tuple(d[2] for d in minibatch))  # torch.Size([*, 1])\n        state_1_batch = torch.cat(tuple(d[3] for d in minibatch))  # torch.Size([*, state_dim])\n\n        state_batch = state_batch.detach()\n        action_batch = action_batch.detach()\n        reward_batch = reward_batch.detach()\n        state_1_batch = state_1_batch.detach()\n\n        if torch.cuda.is_available():\n            state_batch = state_batch.cuda()\n            action_batch = action_batch.cuda()\n            reward_batch = reward_batch.cuda()\n            state_1_batch = state_1_batch.cuda()\n\n        # Loss Calculation for Critic Network\n        next_actions = actor_net_t(state_1_batch)\n        next_Q = critic_net_t(state_1_batch, next_actions)\n        Q_prime = reward_batch + train_options['gamma'] * next_Q\n        Q_pred = critic_net(state_batch, action_batch)\n        critic_loss = critic_criterion(Q_pred, Q_prime.detach())\n\n        # Update Critic Network\n        critic_optimizer.zero_grad()\n        critic_loss.backward()\n        critic_optimizer.step()\n\n        # Loss Calculation for Actor Network\n        actor_loss = torch.mean(-critic_net(state_batch, actor_net(state_batch)))\n\n        # Update Actor Network\n        actor_optimizer.zero_grad()\n        actor_loss.backward()\n        actor_optimizer.step()\n\n        # UPDATE state, epsilon, target network, etc.\n        state = state_1\n        iteration += 1\n        train_options['overall_iter'] += 1  # global counter\n\n        # Update: Target Network\n        if train_options['overall_iter'] % options['target_update'] == 0:\n            actor_params = actor_net.state_dict()\n            critic_params = critic_net.state_dict()\n            actor_t_params = actor_net_t.state_dict()\n            critic_t_params = critic_net_t.state_dict()\n\n            for name in critic_params:\n                critic_params[name] = train_options['tau'] * critic_params[name].clone() + \\\n                                      (1 - train_options['tau']) * critic_t_params[name].clone()\n\n            critic_net_t.load_state_dict(critic_params)\n\n            for name in actor_params:\n                actor_params[name] = train_options['tau'] * actor_params[name].clone() + \\\n                                     (1 - train_options['tau']) * actor_t_params[name].clone()\n\n            actor_net_t.load_state_dict(actor_params)\n\n            # actor_net_t.load_state_dict(actor_net.state_dict())\n            # critic_net_t.load_state_dict(critic_net.state_dict())\n    if (train_options['overall_iter']-1)%500==0:\n        print(\n            \"Beam: %d, Iter: %d, Q: %.4f, Reward pred: %d, Reward: %d, BF Gain pred: %.2f, BF Gain: %.2f, Critic Loss: %.2f, Policy Loss: %.2f\" % \\\n            (beam_id, train_options['overall_iter'],\n             np.max(torch.Tensor.cpu(Q_pred.detach()).numpy().squeeze()),\n             int(torch.Tensor.cpu(reward_pred).numpy().squeeze()),\n             int(torch.Tensor.cpu(reward).numpy().squeeze()),\n             torch.Tensor.cpu(bf_gain_pred.detach()).numpy().squeeze(),\n             torch.Tensor.cpu(bf_gain.detach()).numpy().squeeze(),\n             torch.Tensor.cpu(critic_loss.detach()).numpy().squeeze(),\n             torch.Tensor.cpu(actor_loss.detach()).numpy().squeeze()))\n\n    # Training Communication Interface\n    train_options['replay_memory'] = replay_memory  # used for the next loop\n    train_options['state'] = state  # used for the next loop\n    train_options['best_state'] = CB_Env.best_bf_vec  # used for clustering and assignment\n\n    return train_options","metadata":{"execution":{"iopub.status.busy":"2023-10-06T09:23:22.484141Z","iopub.execute_input":"2023-10-06T09:23:22.484944Z","iopub.status.idle":"2023-10-06T09:23:22.505460Z","shell.execute_reply.started":"2023-10-06T09:23:22.484905Z","shell.execute_reply":"2023-10-06T09:23:22.504310Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with torch.cuda.device(options['gpu_idx']):\n    u_classifier, sensing_beam = KMeans_only(ch, options['num_NNs'], n_bit=options['num_bits'], n_rand_beam=30)\n    np.save('sensing_beam.npy', sensing_beam)\n    sensing_beam = torch.from_numpy(sensing_beam).float().cuda()\n\n    filename = 'kmeans_model.sav'\n    pickle.dump(u_classifier, open(filename, 'wb'))\n\n    # Quantization settings\n    options['num_ph'] = 2 ** options['num_bits']\n    options['multi_step'] = torch.from_numpy(\n        np.linspace(int(-(options['num_ph'] - 2) / 2),\n                    int(options['num_ph'] / 2),\n                    num=options['num_ph'],\n                    endpoint=True)).type(dtype=torch.float32).reshape(1, -1).cuda()\n    options['pi'] = torch.tensor(np.pi).cuda()\n    options['ph_table'] = (2 * options['pi']) / options['num_ph'] * options['multi_step']\n    options['ph_table'].cuda()\n    options['ph_table_rep'] = options['ph_table'].repeat(options['num_ant'], 1)\n\n    # initialize DRL models\n    actor_net_list = []\n    critic_net_list = []\n    actor_net_t_list = []\n    critic_net_t_list = []\n    ounoise_list = []\n    env_list = []\n    train_opt_list = []\n\n    for beam_id in range(options['num_NNs']):\n        actor_net_list.append(Actor(options['num_ant'], options['num_ant']))\n        actor_net_t_list.append(Actor(options['num_ant'], options['num_ant']))\n        critic_net_list.append(Critic(2 * options['num_ant'], 1))\n        critic_net_t_list.append(Critic(2 * options['num_ant'], 1))\n        ounoise_list.append(OUNoise((1, options['num_ant'])))\n        env_list.append(envCB(ch, options['num_ant'], options['num_bits'], beam_id, options))\n        train_opt_list.append(copy.deepcopy(train_opt))\n\n        actor_net_list[beam_id] = actor_net_list[beam_id].cuda()\n        actor_net_t_list[beam_id] = actor_net_t_list[beam_id].cuda()\n        critic_net_list[beam_id] = critic_net_list[beam_id].cuda()\n        critic_net_t_list[beam_id] = critic_net_t_list[beam_id].cuda()\n        actor_net_list[beam_id].apply(init_weights)\n        actor_net_t_list[beam_id].load_state_dict(actor_net_list[beam_id].state_dict())\n        critic_net_list[beam_id].apply(init_weights)\n        critic_net_t_list[beam_id].load_state_dict(critic_net_list[beam_id].state_dict())\n\n    # start_time = time.time()\n\n    # outer loop for randomly sampling users, emulating user dynamics\n    for sample_id in range(options['num_loop']):\n\n        # ---------- Sampling ---------- #\n        n_sample = int(ch.shape[0] * options['ch_sample_ratio'])\n        ch_sample_id = np.random.permutation(ch.shape[0])[0:n_sample]\n        ch_sample = torch.from_numpy(ch[ch_sample_id, :]).float().cuda()\n\n        # ---------- Clustering ---------- #\n#         start_time = time.time()\n\n        bf_mat_sample = bf_gain_cal(sensing_beam, ch_sample)\n        # print(\"Clustering -1 uses %s seconds.\" % (time.time() - start_time))\n        # start_time = time.time()\n        f_matrix = corr_mining(bf_mat_sample)\n        f_matrix_np = torch.Tensor.cpu(f_matrix).numpy()\n        # print(\"Clustering 0 uses %s seconds.\" % (time.time() - start_time))\n        # start_time = time.time()\n        labels = u_classifier.predict(np.transpose(f_matrix_np).astype(float))\n\n        # print(\"Clustering 1 uses %s seconds.\" % (time.time() - start_time))\n        # start_time = time.time()\n\n        user_group = []  # order: clusters\n        ch_group = []  # order: clusters\n        for ii in range(options['num_NNs']):\n            user_group.append(np.where(labels == ii)[0].tolist())\n            ch_group.append(ch_sample[user_group[ii], :])\n\n#         print(\"Clustering 2 uses %s seconds.\" % (time.time() - start_time))\n\n        # ---------- Assignment ---------- #\n#         start_time = time.time()\n\n        # best_state matrix\n        best_beam_mtx = torch.zeros((options['num_NNs'], 2 * options['num_ant'])).float().cuda()\n        for pp in range(options['num_NNs']):\n            best_beam_mtx[pp, :] = env_list[pp].best_bf_vec\n        gain_mtx = bf_gain_cal(best_beam_mtx, ch_sample)  # (n_beam, n_user)\n        for ii in range(options['num_NNs']):\n            if ii == 0:\n                cost_mtx = torch.mean(gain_mtx[:, user_group[ii]], dim=1).reshape(options['num_NNs'], -1)\n            else:\n                sub = torch.mean(gain_mtx[:, user_group[ii]], dim=1).reshape(options['num_NNs'], -1)\n                cost_mtx = torch.cat((cost_mtx, sub), dim=1)\n        cost_mtx = -torch.Tensor.cpu(cost_mtx).numpy()\n        row_ind, col_ind = linear_sum_assignment(cost_mtx)\n        assignment_record = dict(zip(row_ind.tolist(), col_ind.tolist()))  # key: network, value: cluster\n#         print(assignment_record)\n        for ii in range(options['num_NNs']):\n            env_list[ii].ch = ch_group[assignment_record[ii]]\n\n#         print(\"Assignment uses %s seconds.\" % (time.time() - start_time))\n        if (train_opt_list[beam_id]['overall_iter']-1)%500==0 or train_opt_list[beam_id]['overall_iter']==1:\n            start_time = time.time()\n        # ---------- Learning ---------- #\n        for beam_id in range(options['num_NNs']):\n            train_opt_list[beam_id] = train(actor_net_list[beam_id],\n                                            critic_net_list[beam_id],\n                                            actor_net_t_list[beam_id],\n                                            critic_net_t_list[beam_id],\n                                            ounoise_list[beam_id],\n                                            env_list[beam_id],\n                                            options,\n                                            train_opt_list[beam_id],\n                                            beam_id)\n        if (train_opt_list[beam_id]['overall_iter']-1)%500==0: \n            print(\"Training for 500 iteration for each Beam uses %s seconds.\" % (time.time() - start_time))","metadata":{"execution":{"iopub.status.busy":"2023-10-06T09:23:22.507315Z","iopub.execute_input":"2023-10-06T09:23:22.507812Z","iopub.status.idle":"2023-10-06T10:01:30.517254Z","shell.execute_reply.started":"2023-10-06T09:23:22.507776Z","shell.execute_reply":"2023-10-06T10:01:30.515914Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"EGC bf gain:  231.17094\nEGC bf gain:  231.17094\nEGC bf gain:  231.17094\nEGC bf gain:  231.17094\nInitial State Activated.\nInitial State Activated.\nInitial State Activated.\nInitial State Activated.\nBeam: 0, Iter: 501, Q: 1.5306, Reward pred: 1, Reward: 1, BF Gain pred: 14.06, BF Gain: 14.60, Critic Loss: 0.32, Policy Loss: -3.25\nBeam: 1, Iter: 501, Q: 1.5605, Reward pred: 1, Reward: 1, BF Gain pred: 0.95, BF Gain: 1.66, Critic Loss: 0.17, Policy Loss: -3.29\nBeam: 2, Iter: 501, Q: 1.5345, Reward pred: 1, Reward: -1, BF Gain pred: 5.42, BF Gain: 4.46, Critic Loss: 0.33, Policy Loss: -1.45\nBeam: 3, Iter: 501, Q: 1.7296, Reward pred: 1, Reward: 1, BF Gain pred: 20.59, BF Gain: 11.11, Critic Loss: 0.27, Policy Loss: -2.33\nTraining for 500 iteration for each Beam uses 23.962756872177124 seconds.\nBeam: 0, Iter: 1001, Q: 2.4898, Reward pred: 1, Reward: 1, BF Gain pred: 10.56, BF Gain: 15.38, Critic Loss: 0.19, Policy Loss: -2.88\nBeam: 1, Iter: 1001, Q: 3.6161, Reward pred: 1, Reward: 1, BF Gain pred: 8.56, BF Gain: 3.74, Critic Loss: 0.12, Policy Loss: -3.26\nBeam: 2, Iter: 1001, Q: 3.2890, Reward pred: -1, Reward: 1, BF Gain pred: 2.38, BF Gain: 7.24, Critic Loss: 0.17, Policy Loss: -3.11\nBeam: 3, Iter: 1001, Q: 1.4779, Reward pred: -1, Reward: -1, BF Gain pred: 4.29, BF Gain: 3.07, Critic Loss: 0.17, Policy Loss: -2.87\nTraining for 500 iteration for each Beam uses 26.851063013076782 seconds.\nBeam: 0, Iter: 1501, Q: 2.1732, Reward pred: 1, Reward: -1, BF Gain pred: 29.95, BF Gain: 23.37, Critic Loss: 0.17, Policy Loss: -2.92\nBeam: 1, Iter: 1501, Q: 1.4278, Reward pred: 1, Reward: 1, BF Gain pred: 12.51, BF Gain: 14.49, Critic Loss: 0.08, Policy Loss: -2.45\nBeam: 2, Iter: 1501, Q: 1.6292, Reward pred: -1, Reward: -1, BF Gain pred: 4.24, BF Gain: 7.01, Critic Loss: 0.10, Policy Loss: -2.41\nBeam: 3, Iter: 1501, Q: 1.9446, Reward pred: -1, Reward: -1, BF Gain pred: 4.65, BF Gain: 1.32, Critic Loss: 0.14, Policy Loss: -2.78\nTraining for 500 iteration for each Beam uses 26.407923936843872 seconds.\nBeam: 0, Iter: 2001, Q: 1.4042, Reward pred: -1, Reward: -1, BF Gain pred: 6.97, BF Gain: 5.47, Critic Loss: 0.09, Policy Loss: -2.84\nBeam: 1, Iter: 2001, Q: 1.3270, Reward pred: -1, Reward: 1, BF Gain pred: 8.26, BF Gain: 17.13, Critic Loss: 0.06, Policy Loss: -2.42\nBeam: 2, Iter: 2001, Q: 2.4855, Reward pred: -1, Reward: 1, BF Gain pred: 1.53, BF Gain: 8.64, Critic Loss: 0.09, Policy Loss: -2.29\nBeam: 3, Iter: 2001, Q: 1.4161, Reward pred: 1, Reward: -1, BF Gain pred: 14.68, BF Gain: 9.01, Critic Loss: 0.09, Policy Loss: -2.53\nTraining for 500 iteration for each Beam uses 27.177364110946655 seconds.\nBeam: 0, Iter: 2501, Q: 1.6678, Reward pred: -1, Reward: -1, BF Gain pred: 3.17, BF Gain: 3.20, Critic Loss: 0.10, Policy Loss: -2.65\nBeam: 1, Iter: 2501, Q: 1.5649, Reward pred: 1, Reward: 1, BF Gain pred: 18.03, BF Gain: 7.84, Critic Loss: 0.05, Policy Loss: -2.25\nBeam: 2, Iter: 2501, Q: 1.4058, Reward pred: -1, Reward: -1, BF Gain pred: 27.75, BF Gain: 14.31, Critic Loss: 0.09, Policy Loss: -2.12\nBeam: 3, Iter: 2501, Q: 1.4905, Reward pred: 1, Reward: -1, BF Gain pred: 39.03, BF Gain: 18.39, Critic Loss: 0.05, Policy Loss: -2.45\nTraining for 500 iteration for each Beam uses 27.7142653465271 seconds.\nBeam: 0, Iter: 3001, Q: 1.9689, Reward pred: -1, Reward: -1, BF Gain pred: 7.39, BF Gain: 4.65, Critic Loss: 0.09, Policy Loss: -2.45\nBeam: 1, Iter: 3001, Q: 1.5494, Reward pred: -1, Reward: -1, BF Gain pred: 8.92, BF Gain: 1.06, Critic Loss: 0.05, Policy Loss: -1.94\nBeam: 2, Iter: 3001, Q: 1.6935, Reward pred: -1, Reward: 1, BF Gain pred: 2.02, BF Gain: 7.77, Critic Loss: 0.07, Policy Loss: -2.30\nBeam: 3, Iter: 3001, Q: 1.3693, Reward pred: -1, Reward: 1, BF Gain pred: 4.83, BF Gain: 21.83, Critic Loss: 0.06, Policy Loss: -2.36\nTraining for 500 iteration for each Beam uses 27.567344903945923 seconds.\nBeam: 0, Iter: 3501, Q: 1.5631, Reward pred: -1, Reward: -1, BF Gain pred: 36.67, BF Gain: 19.72, Critic Loss: 0.06, Policy Loss: -2.37\nBeam: 1, Iter: 3501, Q: 3.2538, Reward pred: 1, Reward: -1, BF Gain pred: 7.54, BF Gain: 4.27, Critic Loss: 0.05, Policy Loss: -2.18\nBeam: 2, Iter: 3501, Q: 1.5401, Reward pred: -1, Reward: -1, BF Gain pred: 10.16, BF Gain: 7.83, Critic Loss: 0.12, Policy Loss: -2.15\nBeam: 3, Iter: 3501, Q: 1.5609, Reward pred: 1, Reward: -1, BF Gain pred: 55.94, BF Gain: 16.52, Critic Loss: 0.06, Policy Loss: -2.20\nTraining for 500 iteration for each Beam uses 27.606640815734863 seconds.\nBeam: 0, Iter: 4001, Q: 1.5145, Reward pred: -1, Reward: -1, BF Gain pred: 33.95, BF Gain: 10.55, Critic Loss: 0.08, Policy Loss: -2.29\nBeam: 1, Iter: 4001, Q: 3.0260, Reward pred: 1, Reward: -1, BF Gain pred: 11.35, BF Gain: 2.35, Critic Loss: 0.05, Policy Loss: -2.00\nBeam: 2, Iter: 4001, Q: 1.5632, Reward pred: 1, Reward: -1, BF Gain pred: 20.30, BF Gain: 4.44, Critic Loss: 0.11, Policy Loss: -2.08\nBeam: 3, Iter: 4001, Q: 1.3864, Reward pred: 1, Reward: 1, BF Gain pred: 12.72, BF Gain: 13.05, Critic Loss: 0.06, Policy Loss: -2.22\nTraining for 500 iteration for each Beam uses 27.80285334587097 seconds.\nBeam: 0, Iter: 4501, Q: 1.4577, Reward pred: 1, Reward: -1, BF Gain pred: 76.25, BF Gain: 49.08, Critic Loss: 0.06, Policy Loss: -2.23\nBeam: 1, Iter: 4501, Q: 1.3614, Reward pred: 1, Reward: -1, BF Gain pred: 20.61, BF Gain: 10.08, Critic Loss: 0.05, Policy Loss: -1.68\nBeam: 2, Iter: 4501, Q: 1.6646, Reward pred: 1, Reward: -1, BF Gain pred: 23.07, BF Gain: 5.86, Critic Loss: 0.20, Policy Loss: -1.44\nBeam: 3, Iter: 4501, Q: 1.3503, Reward pred: 1, Reward: -1, BF Gain pred: 48.93, BF Gain: 6.23, Critic Loss: 0.05, Policy Loss: -2.06\nTraining for 500 iteration for each Beam uses 28.36639380455017 seconds.\nBeam: 0, Iter: 5001, Q: 1.4506, Reward pred: 1, Reward: -1, BF Gain pred: 106.87, BF Gain: 70.90, Critic Loss: 0.05, Policy Loss: -2.14\nBeam: 1, Iter: 5001, Q: 1.4754, Reward pred: -1, Reward: -1, BF Gain pred: 53.75, BF Gain: 23.84, Critic Loss: 0.05, Policy Loss: -1.61\nBeam: 2, Iter: 5001, Q: 1.6176, Reward pred: 1, Reward: -1, BF Gain pred: 49.14, BF Gain: 5.33, Critic Loss: 0.06, Policy Loss: -2.16\nBeam: 3, Iter: 5001, Q: 1.3564, Reward pred: 1, Reward: -1, BF Gain pred: 114.29, BF Gain: 26.57, Critic Loss: 0.04, Policy Loss: -2.12\nTraining for 500 iteration for each Beam uses 28.06662631034851 seconds.\nBeam: 0, Iter: 5501, Q: 1.6552, Reward pred: -1, Reward: -1, BF Gain pred: 52.53, BF Gain: 25.85, Critic Loss: 0.12, Policy Loss: -1.98\nBeam: 1, Iter: 5501, Q: 1.3629, Reward pred: 1, Reward: -1, BF Gain pred: 45.26, BF Gain: 6.37, Critic Loss: 0.05, Policy Loss: -1.50\nBeam: 2, Iter: 5501, Q: 1.3441, Reward pred: -1, Reward: -1, BF Gain pred: 60.08, BF Gain: 23.18, Critic Loss: 0.06, Policy Loss: -2.19\nBeam: 3, Iter: 5501, Q: 1.5235, Reward pred: -1, Reward: -1, BF Gain pred: 72.42, BF Gain: 4.11, Critic Loss: 0.04, Policy Loss: -1.90\nTraining for 500 iteration for each Beam uses 28.219902515411377 seconds.\nBeam: 0, Iter: 6001, Q: 1.3450, Reward pred: -1, Reward: -1, BF Gain pred: 78.64, BF Gain: 64.37, Critic Loss: 0.04, Policy Loss: -2.21\nBeam: 1, Iter: 6001, Q: 1.6192, Reward pred: -1, Reward: -1, BF Gain pred: 55.00, BF Gain: 7.80, Critic Loss: 0.06, Policy Loss: -1.44\nBeam: 2, Iter: 6001, Q: 1.5996, Reward pred: 1, Reward: -1, BF Gain pred: 73.32, BF Gain: 15.58, Critic Loss: 0.07, Policy Loss: -2.19\nBeam: 3, Iter: 6001, Q: 2.4551, Reward pred: -1, Reward: -1, BF Gain pred: 6.50, BF Gain: 8.55, Critic Loss: 0.27, Policy Loss: -1.10\nTraining for 500 iteration for each Beam uses 28.689992904663086 seconds.\nBeam: 0, Iter: 6501, Q: 1.4040, Reward pred: 1, Reward: -1, BF Gain pred: 114.15, BF Gain: 41.25, Critic Loss: 0.07, Policy Loss: -1.80\nBeam: 1, Iter: 6501, Q: 1.7518, Reward pred: 1, Reward: -1, BF Gain pred: 48.51, BF Gain: 30.96, Critic Loss: 0.07, Policy Loss: -1.55\nBeam: 2, Iter: 6501, Q: 1.5325, Reward pred: 1, Reward: -1, BF Gain pred: 87.29, BF Gain: 17.09, Critic Loss: 0.16, Policy Loss: -2.22\nBeam: 3, Iter: 6501, Q: 1.6861, Reward pred: 1, Reward: -1, BF Gain pred: 148.79, BF Gain: 38.03, Critic Loss: 0.08, Policy Loss: -1.85\nTraining for 500 iteration for each Beam uses 27.88346028327942 seconds.\nBeam: 0, Iter: 7001, Q: 1.7754, Reward pred: -1, Reward: -1, BF Gain pred: 77.15, BF Gain: 30.91, Critic Loss: 0.10, Policy Loss: -1.86\nBeam: 1, Iter: 7001, Q: 1.4928, Reward pred: -1, Reward: -1, BF Gain pred: 41.48, BF Gain: 7.07, Critic Loss: 0.07, Policy Loss: -1.37\nBeam: 2, Iter: 7001, Q: 1.6751, Reward pred: -1, Reward: -1, BF Gain pred: 79.86, BF Gain: 11.45, Critic Loss: 0.19, Policy Loss: -2.20\nBeam: 3, Iter: 7001, Q: 1.8107, Reward pred: -1, Reward: -1, BF Gain pred: 72.48, BF Gain: 7.63, Critic Loss: 0.52, Policy Loss: -1.26\nTraining for 500 iteration for each Beam uses 28.015955686569214 seconds.\nBeam: 0, Iter: 7501, Q: 1.4431, Reward pred: -1, Reward: -1, BF Gain pred: 98.84, BF Gain: 43.51, Critic Loss: 0.06, Policy Loss: -2.23\nBeam: 1, Iter: 7501, Q: 1.2978, Reward pred: -1, Reward: -1, BF Gain pred: 49.25, BF Gain: 14.04, Critic Loss: 0.12, Policy Loss: -1.45\nBeam: 2, Iter: 7501, Q: 1.3625, Reward pred: -1, Reward: -1, BF Gain pred: 80.34, BF Gain: 24.72, Critic Loss: 0.15, Policy Loss: -2.17\nBeam: 3, Iter: 7501, Q: 2.0215, Reward pred: -1, Reward: -1, BF Gain pred: 66.56, BF Gain: 27.34, Critic Loss: 0.33, Policy Loss: -1.17\nTraining for 500 iteration for each Beam uses 27.94386649131775 seconds.\nBeam: 0, Iter: 8001, Q: 1.4576, Reward pred: 1, Reward: -1, BF Gain pred: 118.42, BF Gain: 31.22, Critic Loss: 0.05, Policy Loss: -2.15\nBeam: 1, Iter: 8001, Q: 1.4273, Reward pred: 1, Reward: -1, BF Gain pred: 52.07, BF Gain: 14.94, Critic Loss: 0.24, Policy Loss: -1.04\nBeam: 2, Iter: 8001, Q: 1.6821, Reward pred: 1, Reward: -1, BF Gain pred: 90.14, BF Gain: 42.51, Critic Loss: 0.20, Policy Loss: -2.07\nBeam: 3, Iter: 8001, Q: 1.2908, Reward pred: -1, Reward: -1, BF Gain pred: 118.08, BF Gain: 13.38, Critic Loss: 0.11, Policy Loss: -2.01\nTraining for 500 iteration for each Beam uses 28.00056743621826 seconds.\nBeam: 0, Iter: 8501, Q: 1.3578, Reward pred: -1, Reward: -1, BF Gain pred: 81.75, BF Gain: 25.52, Critic Loss: 0.07, Policy Loss: -1.32\nBeam: 1, Iter: 8501, Q: 1.3851, Reward pred: 1, Reward: -1, BF Gain pred: 56.86, BF Gain: 17.65, Critic Loss: 0.15, Policy Loss: -1.71\nBeam: 2, Iter: 8501, Q: 1.5262, Reward pred: -1, Reward: -1, BF Gain pred: 70.45, BF Gain: 20.13, Critic Loss: 0.10, Policy Loss: -2.30\nBeam: 3, Iter: 8501, Q: 1.5261, Reward pred: 1, Reward: -1, BF Gain pred: 136.97, BF Gain: 46.05, Critic Loss: 0.09, Policy Loss: -1.87\nTraining for 500 iteration for each Beam uses 28.15668487548828 seconds.\nBeam: 0, Iter: 9001, Q: 1.7912, Reward pred: 1, Reward: -1, BF Gain pred: 161.49, BF Gain: 54.89, Critic Loss: 0.09, Policy Loss: -1.28\nBeam: 1, Iter: 9001, Q: 1.4057, Reward pred: 1, Reward: -1, BF Gain pred: 50.23, BF Gain: 38.98, Critic Loss: 0.13, Policy Loss: -1.30\nBeam: 2, Iter: 9001, Q: 1.3820, Reward pred: 1, Reward: -1, BF Gain pred: 57.69, BF Gain: 37.80, Critic Loss: 0.40, Policy Loss: -0.94\nBeam: 3, Iter: 9001, Q: 1.5035, Reward pred: -1, Reward: -1, BF Gain pred: 72.67, BF Gain: 28.13, Critic Loss: 0.08, Policy Loss: -1.74\nTraining for 500 iteration for each Beam uses 28.581939220428467 seconds.\nBeam: 0, Iter: 9501, Q: 1.4610, Reward pred: -1, Reward: -1, BF Gain pred: 123.30, BF Gain: 47.78, Critic Loss: 0.10, Policy Loss: -1.68\nBeam: 1, Iter: 9501, Q: 1.7515, Reward pred: 1, Reward: -1, BF Gain pred: 69.47, BF Gain: 19.76, Critic Loss: 0.19, Policy Loss: -1.22\nBeam: 2, Iter: 9501, Q: 1.7478, Reward pred: -1, Reward: -1, BF Gain pred: 64.79, BF Gain: 19.24, Critic Loss: 0.18, Policy Loss: -1.26\nBeam: 3, Iter: 9501, Q: 1.5953, Reward pred: -1, Reward: -1, BF Gain pred: 116.15, BF Gain: 30.41, Critic Loss: 0.27, Policy Loss: -1.18\nTraining for 500 iteration for each Beam uses 28.25425148010254 seconds.\nBeam: 0, Iter: 10001, Q: 1.4658, Reward pred: 1, Reward: -1, BF Gain pred: 111.84, BF Gain: 29.51, Critic Loss: 0.12, Policy Loss: -1.39\nBeam: 1, Iter: 10001, Q: 1.7478, Reward pred: -1, Reward: -1, BF Gain pred: 65.13, BF Gain: 15.25, Critic Loss: 0.15, Policy Loss: -1.31\nBeam: 2, Iter: 10001, Q: 1.6306, Reward pred: 1, Reward: -1, BF Gain pred: 100.17, BF Gain: 47.60, Critic Loss: 0.16, Policy Loss: -1.27\nBeam: 3, Iter: 10001, Q: 1.4253, Reward pred: -1, Reward: -1, BF Gain pred: 105.27, BF Gain: 57.20, Critic Loss: 0.18, Policy Loss: -1.23\nTraining for 500 iteration for each Beam uses 27.80387306213379 seconds.\nBeam: 0, Iter: 10501, Q: 1.2469, Reward pred: 1, Reward: 1, BF Gain pred: 15.47, BF Gain: 27.30, Critic Loss: 0.50, Policy Loss: -0.96\nBeam: 1, Iter: 10501, Q: 1.5152, Reward pred: -1, Reward: -1, BF Gain pred: 61.89, BF Gain: 15.14, Critic Loss: 0.09, Policy Loss: -1.26\nBeam: 2, Iter: 10501, Q: 1.6751, Reward pred: -1, Reward: -1, BF Gain pred: 100.80, BF Gain: 31.07, Critic Loss: 0.17, Policy Loss: -1.01\nBeam: 3, Iter: 10501, Q: 1.4656, Reward pred: -1, Reward: -1, BF Gain pred: 72.74, BF Gain: 9.01, Critic Loss: 0.12, Policy Loss: -1.23\nTraining for 500 iteration for each Beam uses 28.406415224075317 seconds.\nBeam: 0, Iter: 11001, Q: 1.6438, Reward pred: -1, Reward: -1, BF Gain pred: 102.86, BF Gain: 55.58, Critic Loss: 0.41, Policy Loss: -0.80\nBeam: 1, Iter: 11001, Q: 1.4843, Reward pred: 1, Reward: -1, BF Gain pred: 66.96, BF Gain: 19.00, Critic Loss: 0.18, Policy Loss: -1.10\nBeam: 2, Iter: 11001, Q: 1.2877, Reward pred: -1, Reward: -1, BF Gain pred: 85.08, BF Gain: 22.88, Critic Loss: 0.39, Policy Loss: -0.51\nBeam: 3, Iter: 11001, Q: 1.3632, Reward pred: -1, Reward: -1, BF Gain pred: 119.94, BF Gain: 20.30, Critic Loss: 0.07, Policy Loss: -1.41\nTraining for 500 iteration for each Beam uses 28.476346015930176 seconds.\nBeam: 0, Iter: 11501, Q: 1.4697, Reward pred: 1, Reward: -1, BF Gain pred: 154.96, BF Gain: 54.78, Critic Loss: 0.13, Policy Loss: -1.80\nBeam: 1, Iter: 11501, Q: 1.5424, Reward pred: 1, Reward: -1, BF Gain pred: 67.19, BF Gain: 38.30, Critic Loss: 0.12, Policy Loss: -0.93\nBeam: 2, Iter: 11501, Q: 1.2353, Reward pred: 1, Reward: -1, BF Gain pred: 116.94, BF Gain: 28.99, Critic Loss: 0.18, Policy Loss: -0.83\nBeam: 3, Iter: 11501, Q: 1.3418, Reward pred: -1, Reward: -1, BF Gain pred: 129.02, BF Gain: 87.54, Critic Loss: 0.11, Policy Loss: -0.75\nTraining for 500 iteration for each Beam uses 28.914026975631714 seconds.\nBeam: 0, Iter: 12001, Q: 1.8018, Reward pred: 1, Reward: -1, BF Gain pred: 145.31, BF Gain: 44.20, Critic Loss: 0.13, Policy Loss: -1.67\nBeam: 1, Iter: 12001, Q: 1.8094, Reward pred: -1, Reward: -1, BF Gain pred: 60.81, BF Gain: 12.14, Critic Loss: 0.12, Policy Loss: -0.85\nBeam: 2, Iter: 12001, Q: 1.5898, Reward pred: 1, Reward: -1, BF Gain pred: 96.39, BF Gain: 24.46, Critic Loss: 0.10, Policy Loss: -1.07\nBeam: 3, Iter: 12001, Q: 1.4401, Reward pred: 1, Reward: -1, BF Gain pred: 142.85, BF Gain: 57.90, Critic Loss: 0.18, Policy Loss: -0.45\nTraining for 500 iteration for each Beam uses 28.91264510154724 seconds.\nBeam: 0, Iter: 12501, Q: 1.5135, Reward pred: -1, Reward: -1, BF Gain pred: 126.16, BF Gain: 26.47, Critic Loss: 0.13, Policy Loss: -1.59\nBeam: 1, Iter: 12501, Q: 1.6921, Reward pred: -1, Reward: -1, BF Gain pred: 64.59, BF Gain: 19.76, Critic Loss: 0.08, Policy Loss: -1.19\nBeam: 2, Iter: 12501, Q: 1.4555, Reward pred: -1, Reward: -1, BF Gain pred: 105.11, BF Gain: 22.86, Critic Loss: 0.09, Policy Loss: -1.07\nBeam: 3, Iter: 12501, Q: 1.7871, Reward pred: -1, Reward: -1, BF Gain pred: 103.77, BF Gain: 21.19, Critic Loss: 0.07, Policy Loss: -0.47\nTraining for 500 iteration for each Beam uses 28.275182962417603 seconds.\nBeam: 0, Iter: 13001, Q: 1.6474, Reward pred: -1, Reward: -1, BF Gain pred: 144.09, BF Gain: 21.62, Critic Loss: 0.11, Policy Loss: -1.26\nBeam: 1, Iter: 13001, Q: 1.5571, Reward pred: -1, Reward: -1, BF Gain pred: 59.25, BF Gain: 10.54, Critic Loss: 0.16, Policy Loss: -0.75\nBeam: 2, Iter: 13001, Q: 1.4054, Reward pred: -1, Reward: -1, BF Gain pred: 109.07, BF Gain: 46.00, Critic Loss: 0.17, Policy Loss: -0.67\nBeam: 3, Iter: 13001, Q: 1.5710, Reward pred: 1, Reward: -1, BF Gain pred: 163.85, BF Gain: 24.01, Critic Loss: 0.09, Policy Loss: -0.60\nTraining for 500 iteration for each Beam uses 28.28251624107361 seconds.\nBeam: 0, Iter: 13501, Q: 1.5233, Reward pred: -1, Reward: -1, BF Gain pred: 141.57, BF Gain: 28.05, Critic Loss: 0.12, Policy Loss: -1.26\nBeam: 1, Iter: 13501, Q: 1.4959, Reward pred: 1, Reward: -1, BF Gain pred: 59.64, BF Gain: 19.67, Critic Loss: 0.10, Policy Loss: -0.88\nBeam: 2, Iter: 13501, Q: 1.4901, Reward pred: 1, Reward: -1, BF Gain pred: 102.70, BF Gain: 25.75, Critic Loss: 0.07, Policy Loss: -0.79\nBeam: 3, Iter: 13501, Q: 1.5653, Reward pred: 1, Reward: -1, BF Gain pred: 154.41, BF Gain: 54.81, Critic Loss: 0.06, Policy Loss: -0.89\nTraining for 500 iteration for each Beam uses 28.210966110229492 seconds.\nBeam: 0, Iter: 14001, Q: 1.5589, Reward pred: 1, Reward: -1, BF Gain pred: 153.72, BF Gain: 80.27, Critic Loss: 0.11, Policy Loss: -1.28\nBeam: 1, Iter: 14001, Q: 1.7596, Reward pred: -1, Reward: -1, BF Gain pred: 66.43, BF Gain: 12.76, Critic Loss: 0.13, Policy Loss: -0.79\nBeam: 2, Iter: 14001, Q: 1.5221, Reward pred: -1, Reward: -1, BF Gain pred: 113.19, BF Gain: 31.22, Critic Loss: 0.14, Policy Loss: -0.75\nBeam: 3, Iter: 14001, Q: 1.4943, Reward pred: -1, Reward: -1, BF Gain pred: 162.09, BF Gain: 52.10, Critic Loss: 0.08, Policy Loss: -0.76\nTraining for 500 iteration for each Beam uses 28.345953464508057 seconds.\nBeam: 0, Iter: 14501, Q: 1.3787, Reward pred: 1, Reward: -1, BF Gain pred: 157.24, BF Gain: 45.68, Critic Loss: 0.08, Policy Loss: -1.27\nBeam: 1, Iter: 14501, Q: 1.5594, Reward pred: 1, Reward: -1, BF Gain pred: 55.61, BF Gain: 7.68, Critic Loss: 0.13, Policy Loss: -0.83\nBeam: 2, Iter: 14501, Q: 1.7523, Reward pred: 1, Reward: -1, BF Gain pred: 114.15, BF Gain: 39.38, Critic Loss: 0.07, Policy Loss: -0.90\nBeam: 3, Iter: 14501, Q: 1.4230, Reward pred: 1, Reward: -1, BF Gain pred: 160.01, BF Gain: 38.05, Critic Loss: 0.12, Policy Loss: -0.76\nTraining for 500 iteration for each Beam uses 27.67671012878418 seconds.\nBeam: 0, Iter: 15001, Q: 1.6433, Reward pred: -1, Reward: -1, BF Gain pred: 135.55, BF Gain: 23.14, Critic Loss: 0.06, Policy Loss: -1.18\nBeam: 1, Iter: 15001, Q: 1.5196, Reward pred: 1, Reward: -1, BF Gain pred: 70.75, BF Gain: 27.76, Critic Loss: 0.13, Policy Loss: -0.82\nBeam: 2, Iter: 15001, Q: 1.5042, Reward pred: 1, Reward: -1, BF Gain pred: 113.80, BF Gain: 19.95, Critic Loss: 0.08, Policy Loss: -1.02\nBeam: 3, Iter: 15001, Q: 1.5513, Reward pred: 1, Reward: -1, BF Gain pred: 129.33, BF Gain: 37.09, Critic Loss: 0.07, Policy Loss: -1.03\nTraining for 500 iteration for each Beam uses 28.09012484550476 seconds.\nBeam: 0, Iter: 15501, Q: 0.8643, Reward pred: -1, Reward: -1, BF Gain pred: 131.45, BF Gain: 63.31, Critic Loss: 0.34, Policy Loss: -0.46\nBeam: 1, Iter: 15501, Q: 1.6318, Reward pred: 1, Reward: -1, BF Gain pred: 77.19, BF Gain: 24.50, Critic Loss: 0.10, Policy Loss: -1.01\nBeam: 2, Iter: 15501, Q: 1.3204, Reward pred: 1, Reward: -1, BF Gain pred: 110.16, BF Gain: 17.74, Critic Loss: 0.06, Policy Loss: -1.00\nBeam: 3, Iter: 15501, Q: 1.3730, Reward pred: 1, Reward: -1, BF Gain pred: 172.23, BF Gain: 13.52, Critic Loss: 0.06, Policy Loss: -0.97\nTraining for 500 iteration for each Beam uses 27.741268157958984 seconds.\nBeam: 0, Iter: 16001, Q: 1.7535, Reward pred: 1, Reward: -1, BF Gain pred: 116.86, BF Gain: 35.22, Critic Loss: 0.17, Policy Loss: -0.83\nBeam: 1, Iter: 16001, Q: 1.4864, Reward pred: -1, Reward: -1, BF Gain pred: 72.43, BF Gain: 36.55, Critic Loss: 0.08, Policy Loss: -1.03\nBeam: 2, Iter: 16001, Q: 1.5795, Reward pred: -1, Reward: -1, BF Gain pred: 101.76, BF Gain: 16.15, Critic Loss: 0.09, Policy Loss: -0.84\nBeam: 3, Iter: 16001, Q: 1.3349, Reward pred: -1, Reward: -1, BF Gain pred: 136.32, BF Gain: 53.14, Critic Loss: 0.04, Policy Loss: -0.98\nTraining for 500 iteration for each Beam uses 27.586586952209473 seconds.\nBeam: 0, Iter: 16501, Q: 1.5293, Reward pred: 1, Reward: -1, BF Gain pred: 175.78, BF Gain: 75.09, Critic Loss: 0.09, Policy Loss: -0.93\nBeam: 1, Iter: 16501, Q: 1.4480, Reward pred: -1, Reward: -1, BF Gain pred: 57.91, BF Gain: 32.69, Critic Loss: 0.08, Policy Loss: -0.95\nBeam: 2, Iter: 16501, Q: 1.6704, Reward pred: -1, Reward: -1, BF Gain pred: 102.66, BF Gain: 33.57, Critic Loss: 0.07, Policy Loss: -0.89\nBeam: 3, Iter: 16501, Q: 1.5673, Reward pred: 1, Reward: -1, BF Gain pred: 151.02, BF Gain: 44.74, Critic Loss: 0.07, Policy Loss: -0.90\nTraining for 500 iteration for each Beam uses 27.765371799468994 seconds.\nBeam: 0, Iter: 17001, Q: 0.9628, Reward pred: -1, Reward: -1, BF Gain pred: 144.42, BF Gain: 66.53, Critic Loss: 0.26, Policy Loss: -0.36\nBeam: 1, Iter: 17001, Q: 0.5817, Reward pred: 1, Reward: -1, BF Gain pred: 80.94, BF Gain: 21.87, Critic Loss: 0.36, Policy Loss: -0.14\nBeam: 2, Iter: 17001, Q: 1.4104, Reward pred: -1, Reward: -1, BF Gain pred: 106.79, BF Gain: 35.78, Critic Loss: 0.05, Policy Loss: -1.00\nBeam: 3, Iter: 17001, Q: 1.5599, Reward pred: -1, Reward: -1, BF Gain pred: 161.08, BF Gain: 46.62, Critic Loss: 0.10, Policy Loss: -0.66\nTraining for 500 iteration for each Beam uses 27.926398277282715 seconds.\nBeam: 0, Iter: 17501, Q: 1.5181, Reward pred: 1, Reward: -1, BF Gain pred: 167.67, BF Gain: 37.50, Critic Loss: 0.08, Policy Loss: -0.87\nBeam: 1, Iter: 17501, Q: 1.6909, Reward pred: 1, Reward: -1, BF Gain pred: 71.18, BF Gain: 26.41, Critic Loss: 0.12, Policy Loss: -0.72\nBeam: 2, Iter: 17501, Q: 1.7799, Reward pred: 1, Reward: -1, BF Gain pred: 125.44, BF Gain: 47.78, Critic Loss: 0.06, Policy Loss: -0.95\nBeam: 3, Iter: 17501, Q: 1.4830, Reward pred: 1, Reward: -1, BF Gain pred: 182.50, BF Gain: 86.98, Critic Loss: 0.06, Policy Loss: -0.90\nTraining for 500 iteration for each Beam uses 28.505696058273315 seconds.\nBeam: 0, Iter: 18001, Q: 1.7329, Reward pred: 1, Reward: -1, BF Gain pred: 170.80, BF Gain: 38.87, Critic Loss: 0.10, Policy Loss: -0.99\nBeam: 1, Iter: 18001, Q: 1.3046, Reward pred: 1, Reward: -1, BF Gain pred: 79.33, BF Gain: 15.13, Critic Loss: 0.11, Policy Loss: -0.99\nBeam: 2, Iter: 18001, Q: 1.4945, Reward pred: -1, Reward: -1, BF Gain pred: 124.47, BF Gain: 62.82, Critic Loss: 0.11, Policy Loss: -0.64\nBeam: 3, Iter: 18001, Q: 1.7682, Reward pred: -1, Reward: -1, BF Gain pred: 159.84, BF Gain: 54.48, Critic Loss: 0.07, Policy Loss: -0.88\nTraining for 500 iteration for each Beam uses 28.961562633514404 seconds.\nBeam: 0, Iter: 18501, Q: 1.5763, Reward pred: -1, Reward: -1, BF Gain pred: 140.49, BF Gain: 48.96, Critic Loss: 0.08, Policy Loss: -0.96\nBeam: 1, Iter: 18501, Q: 1.4376, Reward pred: 1, Reward: -1, BF Gain pred: 71.34, BF Gain: 13.62, Critic Loss: 0.09, Policy Loss: -1.01\nBeam: 2, Iter: 18501, Q: 1.3677, Reward pred: -1, Reward: -1, BF Gain pred: 123.20, BF Gain: 39.28, Critic Loss: 0.07, Policy Loss: -1.07\nBeam: 3, Iter: 18501, Q: 1.5695, Reward pred: 1, Reward: -1, BF Gain pred: 155.08, BF Gain: 52.53, Critic Loss: 0.06, Policy Loss: -0.85\nTraining for 500 iteration for each Beam uses 29.226369857788086 seconds.\nBeam: 0, Iter: 19001, Q: 2.8933, Reward pred: -1, Reward: -1, BF Gain pred: 165.47, BF Gain: 36.89, Critic Loss: 0.09, Policy Loss: -1.07\nBeam: 1, Iter: 19001, Q: 0.5180, Reward pred: 1, Reward: -1, BF Gain pred: 79.53, BF Gain: 51.40, Critic Loss: 0.38, Policy Loss: -0.20\nBeam: 2, Iter: 19001, Q: 1.7638, Reward pred: -1, Reward: -1, BF Gain pred: 127.64, BF Gain: 45.43, Critic Loss: 0.06, Policy Loss: -1.11\nBeam: 3, Iter: 19001, Q: 1.2595, Reward pred: 1, Reward: -1, BF Gain pred: 169.13, BF Gain: 21.53, Critic Loss: 0.04, Policy Loss: -1.02\nTraining for 500 iteration for each Beam uses 28.732183694839478 seconds.\nBeam: 0, Iter: 19501, Q: 1.8023, Reward pred: 1, Reward: -1, BF Gain pred: 168.61, BF Gain: 73.28, Critic Loss: 0.08, Policy Loss: -1.07\nBeam: 1, Iter: 19501, Q: 1.7455, Reward pred: -1, Reward: -1, BF Gain pred: 69.82, BF Gain: 26.65, Critic Loss: 0.15, Policy Loss: -0.66\nBeam: 2, Iter: 19501, Q: 1.5259, Reward pred: -1, Reward: -1, BF Gain pred: 110.25, BF Gain: 13.42, Critic Loss: 0.06, Policy Loss: -1.15\nBeam: 3, Iter: 19501, Q: 1.5447, Reward pred: 1, Reward: -1, BF Gain pred: 163.43, BF Gain: 88.72, Critic Loss: 0.05, Policy Loss: -0.95\nTraining for 500 iteration for each Beam uses 29.128944396972656 seconds.\nBeam: 0, Iter: 20001, Q: 1.6960, Reward pred: 1, Reward: -1, BF Gain pred: 171.94, BF Gain: 52.00, Critic Loss: 0.11, Policy Loss: -0.81\nBeam: 1, Iter: 20001, Q: 1.7100, Reward pred: 1, Reward: -1, BF Gain pred: 76.82, BF Gain: 20.98, Critic Loss: 0.09, Policy Loss: -1.00\nBeam: 2, Iter: 20001, Q: 1.5417, Reward pred: 1, Reward: -1, BF Gain pred: 122.50, BF Gain: 39.99, Critic Loss: 0.06, Policy Loss: -0.98\nBeam: 3, Iter: 20001, Q: 0.9589, Reward pred: -1, Reward: -1, BF Gain pred: 159.28, BF Gain: 18.24, Critic Loss: 0.24, Policy Loss: -0.43\nTraining for 500 iteration for each Beam uses 29.217641353607178 seconds.\nBeam: 0, Iter: 20501, Q: 1.6677, Reward pred: 1, Reward: -1, BF Gain pred: 155.44, BF Gain: 55.32, Critic Loss: 0.10, Policy Loss: -0.94\nBeam: 1, Iter: 20501, Q: 1.1358, Reward pred: 1, Reward: -1, BF Gain pred: 80.31, BF Gain: 19.10, Critic Loss: 0.16, Policy Loss: -0.77\nBeam: 2, Iter: 20501, Q: 1.5343, Reward pred: 1, Reward: -1, BF Gain pred: 114.25, BF Gain: 34.04, Critic Loss: 0.07, Policy Loss: -1.10\nBeam: 3, Iter: 20501, Q: 1.3526, Reward pred: -1, Reward: -1, BF Gain pred: 167.95, BF Gain: 73.88, Critic Loss: 0.09, Policy Loss: -0.77\nTraining for 500 iteration for each Beam uses 28.81160879135132 seconds.\nBeam: 0, Iter: 21001, Q: 2.1414, Reward pred: -1, Reward: -1, BF Gain pred: 167.99, BF Gain: 41.38, Critic Loss: 0.17, Policy Loss: -1.08\nBeam: 1, Iter: 21001, Q: 1.4922, Reward pred: 1, Reward: -1, BF Gain pred: 78.40, BF Gain: 30.52, Critic Loss: 0.10, Policy Loss: -0.86\nBeam: 2, Iter: 21001, Q: 2.0444, Reward pred: 1, Reward: -1, BF Gain pred: 129.69, BF Gain: 58.53, Critic Loss: 0.06, Policy Loss: -1.14\nBeam: 3, Iter: 21001, Q: 1.6450, Reward pred: 1, Reward: -1, BF Gain pred: 182.65, BF Gain: 72.69, Critic Loss: 0.06, Policy Loss: -0.90\nTraining for 500 iteration for each Beam uses 28.539075136184692 seconds.\nBeam: 0, Iter: 21501, Q: 1.5974, Reward pred: 1, Reward: -1, BF Gain pred: 159.14, BF Gain: 56.71, Critic Loss: 0.08, Policy Loss: -0.99\nBeam: 1, Iter: 21501, Q: 1.3024, Reward pred: -1, Reward: -1, BF Gain pred: 73.00, BF Gain: 7.87, Critic Loss: 0.14, Policy Loss: -0.83\nBeam: 2, Iter: 21501, Q: 1.3839, Reward pred: 1, Reward: -1, BF Gain pred: 126.70, BF Gain: 57.34, Critic Loss: 0.06, Policy Loss: -1.07\nBeam: 3, Iter: 21501, Q: 1.2147, Reward pred: 1, Reward: -1, BF Gain pred: 187.62, BF Gain: 20.26, Critic Loss: 0.19, Policy Loss: -0.58\nTraining for 500 iteration for each Beam uses 28.56722593307495 seconds.\nBeam: 0, Iter: 22001, Q: 1.2592, Reward pred: 1, Reward: -1, BF Gain pred: 156.25, BF Gain: 58.29, Critic Loss: 0.13, Policy Loss: -0.74\nBeam: 1, Iter: 22001, Q: 1.4866, Reward pred: -1, Reward: -1, BF Gain pred: 79.80, BF Gain: 21.82, Critic Loss: 0.12, Policy Loss: -0.75\nBeam: 2, Iter: 22001, Q: 1.2662, Reward pred: -1, Reward: -1, BF Gain pred: 108.59, BF Gain: 37.12, Critic Loss: 0.06, Policy Loss: -1.16\nBeam: 3, Iter: 22001, Q: 1.5300, Reward pred: 1, Reward: -1, BF Gain pred: 186.24, BF Gain: 56.50, Critic Loss: 0.09, Policy Loss: -0.71\nTraining for 500 iteration for each Beam uses 28.33792471885681 seconds.\nBeam: 0, Iter: 22501, Q: 1.4080, Reward pred: 1, Reward: -1, BF Gain pred: 159.43, BF Gain: 24.51, Critic Loss: 0.11, Policy Loss: -0.84\nBeam: 1, Iter: 22501, Q: 1.4317, Reward pred: 1, Reward: -1, BF Gain pred: 80.44, BF Gain: 7.99, Critic Loss: 0.09, Policy Loss: -0.99\nBeam: 2, Iter: 22501, Q: 1.8268, Reward pred: -1, Reward: -1, BF Gain pred: 106.10, BF Gain: 31.26, Critic Loss: 0.06, Policy Loss: -1.19\nBeam: 3, Iter: 22501, Q: 1.2801, Reward pred: 1, Reward: -1, BF Gain pred: 188.55, BF Gain: 27.09, Critic Loss: 0.09, Policy Loss: -0.75\nTraining for 500 iteration for each Beam uses 28.358638763427734 seconds.\nBeam: 0, Iter: 23001, Q: 1.5741, Reward pred: -1, Reward: -1, BF Gain pred: 155.29, BF Gain: 40.09, Critic Loss: 0.10, Policy Loss: -0.91\nBeam: 1, Iter: 23001, Q: 1.5940, Reward pred: -1, Reward: -1, BF Gain pred: 79.36, BF Gain: 21.64, Critic Loss: 0.23, Policy Loss: -0.40\nBeam: 2, Iter: 23001, Q: 1.4618, Reward pred: -1, Reward: -1, BF Gain pred: 125.73, BF Gain: 66.17, Critic Loss: 0.06, Policy Loss: -1.11\nBeam: 3, Iter: 23001, Q: 1.5192, Reward pred: -1, Reward: -1, BF Gain pred: 170.47, BF Gain: 45.47, Critic Loss: 0.07, Policy Loss: -0.95\nTraining for 500 iteration for each Beam uses 28.420544147491455 seconds.\nBeam: 0, Iter: 23501, Q: 1.4921, Reward pred: -1, Reward: -1, BF Gain pred: 172.51, BF Gain: 54.70, Critic Loss: 0.11, Policy Loss: -0.90\nBeam: 1, Iter: 23501, Q: 1.3890, Reward pred: -1, Reward: -1, BF Gain pred: 59.77, BF Gain: 13.52, Critic Loss: 0.10, Policy Loss: -0.86\nBeam: 2, Iter: 23501, Q: 1.8006, Reward pred: 1, Reward: -1, BF Gain pred: 122.32, BF Gain: 54.37, Critic Loss: 0.05, Policy Loss: -1.03\nBeam: 3, Iter: 23501, Q: 1.4004, Reward pred: 1, Reward: -1, BF Gain pred: 177.32, BF Gain: 85.74, Critic Loss: 0.06, Policy Loss: -0.95\nTraining for 500 iteration for each Beam uses 28.615647792816162 seconds.\nBeam: 0, Iter: 24001, Q: 1.4280, Reward pred: 1, Reward: -1, BF Gain pred: 163.08, BF Gain: 56.80, Critic Loss: 0.09, Policy Loss: -1.09\nBeam: 1, Iter: 24001, Q: 1.7932, Reward pred: 1, Reward: -1, BF Gain pred: 71.60, BF Gain: 14.05, Critic Loss: 0.08, Policy Loss: -0.93\nBeam: 2, Iter: 24001, Q: 1.4636, Reward pred: 1, Reward: -1, BF Gain pred: 131.96, BF Gain: 58.86, Critic Loss: 0.05, Policy Loss: -0.94\nBeam: 3, Iter: 24001, Q: 1.3591, Reward pred: 1, Reward: -1, BF Gain pred: 178.95, BF Gain: 83.16, Critic Loss: 0.07, Policy Loss: -0.93\nTraining for 500 iteration for each Beam uses 27.762394189834595 seconds.\nBeam: 0, Iter: 24501, Q: 1.7177, Reward pred: 1, Reward: -1, BF Gain pred: 150.22, BF Gain: 62.51, Critic Loss: 0.10, Policy Loss: -1.03\nBeam: 1, Iter: 24501, Q: 1.1511, Reward pred: -1, Reward: -1, BF Gain pred: 73.84, BF Gain: 15.03, Critic Loss: 0.17, Policy Loss: -0.59\nBeam: 2, Iter: 24501, Q: 1.3895, Reward pred: 1, Reward: -1, BF Gain pred: 120.21, BF Gain: 64.59, Critic Loss: 0.06, Policy Loss: -0.96\nBeam: 3, Iter: 24501, Q: 1.5262, Reward pred: 1, Reward: -1, BF Gain pred: 179.44, BF Gain: 44.57, Critic Loss: 0.06, Policy Loss: -0.91\nTraining for 500 iteration for each Beam uses 28.57991075515747 seconds.\nBeam: 0, Iter: 25001, Q: 1.3773, Reward pred: -1, Reward: -1, BF Gain pred: 156.32, BF Gain: 36.02, Critic Loss: 0.07, Policy Loss: -1.12\nBeam: 1, Iter: 25001, Q: 1.4954, Reward pred: 1, Reward: -1, BF Gain pred: 81.76, BF Gain: 35.16, Critic Loss: 0.13, Policy Loss: -0.74\nBeam: 2, Iter: 25001, Q: 1.4762, Reward pred: 1, Reward: -1, BF Gain pred: 120.68, BF Gain: 51.12, Critic Loss: 0.05, Policy Loss: -0.99\nBeam: 3, Iter: 25001, Q: 2.1220, Reward pred: 1, Reward: -1, BF Gain pred: 163.28, BF Gain: 60.66, Critic Loss: 0.07, Policy Loss: -0.97\nTraining for 500 iteration for each Beam uses 28.810673236846924 seconds.\nBeam: 0, Iter: 25501, Q: 1.7905, Reward pred: -1, Reward: -1, BF Gain pred: 159.55, BF Gain: 36.18, Critic Loss: 0.05, Policy Loss: -1.04\nBeam: 1, Iter: 25501, Q: 1.6136, Reward pred: 1, Reward: -1, BF Gain pred: 74.92, BF Gain: 29.87, Critic Loss: 0.10, Policy Loss: -0.87\nBeam: 2, Iter: 25501, Q: 1.5648, Reward pred: -1, Reward: -1, BF Gain pred: 128.39, BF Gain: 49.44, Critic Loss: 0.05, Policy Loss: -0.99\nBeam: 3, Iter: 25501, Q: 1.3935, Reward pred: 1, Reward: -1, BF Gain pred: 196.28, BF Gain: 80.94, Critic Loss: 0.08, Policy Loss: -0.94\nTraining for 500 iteration for each Beam uses 28.523845195770264 seconds.\nBeam: 0, Iter: 26001, Q: 2.2538, Reward pred: -1, Reward: -1, BF Gain pred: 175.16, BF Gain: 58.52, Critic Loss: 0.10, Policy Loss: -1.02\nBeam: 1, Iter: 26001, Q: 1.5942, Reward pred: 1, Reward: -1, BF Gain pred: 75.20, BF Gain: 23.18, Critic Loss: 0.09, Policy Loss: -0.98\nBeam: 2, Iter: 26001, Q: 1.3812, Reward pred: 1, Reward: -1, BF Gain pred: 128.07, BF Gain: 81.13, Critic Loss: 0.05, Policy Loss: -0.99\nBeam: 3, Iter: 26001, Q: 1.4816, Reward pred: -1, Reward: -1, BF Gain pred: 158.15, BF Gain: 90.40, Critic Loss: 0.07, Policy Loss: -0.95\nTraining for 500 iteration for each Beam uses 28.532369136810303 seconds.\nBeam: 0, Iter: 26501, Q: 1.4289, Reward pred: -1, Reward: -1, BF Gain pred: 160.24, BF Gain: 86.08, Critic Loss: 0.06, Policy Loss: -1.12\nBeam: 1, Iter: 26501, Q: 1.5048, Reward pred: 1, Reward: -1, BF Gain pred: 77.40, BF Gain: 24.64, Critic Loss: 0.09, Policy Loss: -0.90\nBeam: 2, Iter: 26501, Q: 1.5064, Reward pred: 1, Reward: -1, BF Gain pred: 121.30, BF Gain: 40.64, Critic Loss: 0.05, Policy Loss: -1.09\nBeam: 3, Iter: 26501, Q: 1.5052, Reward pred: -1, Reward: -1, BF Gain pred: 188.37, BF Gain: 140.79, Critic Loss: 0.05, Policy Loss: -0.95\nTraining for 500 iteration for each Beam uses 28.784391403198242 seconds.\nBeam: 0, Iter: 27001, Q: 1.5291, Reward pred: -1, Reward: -1, BF Gain pred: 171.14, BF Gain: 93.81, Critic Loss: 0.07, Policy Loss: -1.00\nBeam: 1, Iter: 27001, Q: 1.6853, Reward pred: -1, Reward: -1, BF Gain pred: 77.89, BF Gain: 25.44, Critic Loss: 0.14, Policy Loss: -0.86\nBeam: 2, Iter: 27001, Q: 1.3961, Reward pred: 1, Reward: -1, BF Gain pred: 127.25, BF Gain: 49.91, Critic Loss: 0.07, Policy Loss: -1.11\nBeam: 3, Iter: 27001, Q: 1.4236, Reward pred: -1, Reward: -1, BF Gain pred: 182.85, BF Gain: 35.66, Critic Loss: 0.06, Policy Loss: -0.76\nTraining for 500 iteration for each Beam uses 28.695880889892578 seconds.\nBeam: 0, Iter: 27501, Q: 1.3377, Reward pred: 1, Reward: -1, BF Gain pred: 165.20, BF Gain: 63.95, Critic Loss: 0.08, Policy Loss: -1.01\nBeam: 1, Iter: 27501, Q: 1.5712, Reward pred: 1, Reward: -1, BF Gain pred: 80.28, BF Gain: 47.89, Critic Loss: 0.11, Policy Loss: -1.03\nBeam: 2, Iter: 27501, Q: 1.5916, Reward pred: -1, Reward: -1, BF Gain pred: 129.61, BF Gain: 46.78, Critic Loss: 0.06, Policy Loss: -0.99\nBeam: 3, Iter: 27501, Q: 1.4790, Reward pred: -1, Reward: -1, BF Gain pred: 151.26, BF Gain: 50.96, Critic Loss: 0.05, Policy Loss: -0.91\nTraining for 500 iteration for each Beam uses 28.732356548309326 seconds.\nBeam: 0, Iter: 28001, Q: 1.6080, Reward pred: -1, Reward: -1, BF Gain pred: 168.61, BF Gain: 29.91, Critic Loss: 0.07, Policy Loss: -1.04\nBeam: 1, Iter: 28001, Q: 1.3511, Reward pred: -1, Reward: -1, BF Gain pred: 73.01, BF Gain: 24.46, Critic Loss: 0.10, Policy Loss: -1.03\nBeam: 2, Iter: 28001, Q: 1.4914, Reward pred: -1, Reward: -1, BF Gain pred: 128.85, BF Gain: 42.79, Critic Loss: 0.06, Policy Loss: -1.02\nBeam: 3, Iter: 28001, Q: 1.6697, Reward pred: -1, Reward: -1, BF Gain pred: 171.22, BF Gain: 96.64, Critic Loss: 0.08, Policy Loss: -0.81\nTraining for 500 iteration for each Beam uses 28.55223035812378 seconds.\nBeam: 0, Iter: 28501, Q: 1.5385, Reward pred: -1, Reward: -1, BF Gain pred: 153.14, BF Gain: 78.78, Critic Loss: 0.11, Policy Loss: -1.00\nBeam: 1, Iter: 28501, Q: 0.3280, Reward pred: -1, Reward: -1, BF Gain pred: 78.44, BF Gain: 22.02, Critic Loss: 0.47, Policy Loss: -0.14\nBeam: 2, Iter: 28501, Q: 1.6580, Reward pred: -1, Reward: -1, BF Gain pred: 129.66, BF Gain: 49.36, Critic Loss: 0.05, Policy Loss: -1.11\nBeam: 3, Iter: 28501, Q: 1.6797, Reward pred: -1, Reward: -1, BF Gain pred: 186.09, BF Gain: 66.07, Critic Loss: 0.08, Policy Loss: -0.94\nTraining for 500 iteration for each Beam uses 28.79764986038208 seconds.\nBeam: 0, Iter: 29001, Q: 1.4461, Reward pred: -1, Reward: -1, BF Gain pred: 147.13, BF Gain: 64.27, Critic Loss: 0.10, Policy Loss: -1.07\nBeam: 1, Iter: 29001, Q: 1.5995, Reward pred: 1, Reward: -1, BF Gain pred: 81.12, BF Gain: 38.66, Critic Loss: 0.17, Policy Loss: -0.81\nBeam: 2, Iter: 29001, Q: 1.9318, Reward pred: -1, Reward: -1, BF Gain pred: 121.91, BF Gain: 49.90, Critic Loss: 0.05, Policy Loss: -1.01\nBeam: 3, Iter: 29001, Q: 1.4806, Reward pred: -1, Reward: -1, BF Gain pred: 176.85, BF Gain: 42.02, Critic Loss: 0.06, Policy Loss: -0.92\nTraining for 500 iteration for each Beam uses 28.474426984786987 seconds.\nBeam: 0, Iter: 29501, Q: 1.4374, Reward pred: -1, Reward: -1, BF Gain pred: 160.00, BF Gain: 70.83, Critic Loss: 0.08, Policy Loss: -1.16\nBeam: 1, Iter: 29501, Q: 1.1345, Reward pred: -1, Reward: -1, BF Gain pred: 76.56, BF Gain: 45.78, Critic Loss: 0.23, Policy Loss: -0.39\nBeam: 2, Iter: 29501, Q: 1.5575, Reward pred: 1, Reward: -1, BF Gain pred: 129.54, BF Gain: 28.87, Critic Loss: 0.08, Policy Loss: -1.09\nBeam: 3, Iter: 29501, Q: 1.3804, Reward pred: 1, Reward: -1, BF Gain pred: 170.24, BF Gain: 81.76, Critic Loss: 0.04, Policy Loss: -0.87\nTraining for 500 iteration for each Beam uses 29.03471541404724 seconds.\nBeam: 0, Iter: 30001, Q: 1.4506, Reward pred: -1, Reward: -1, BF Gain pred: 168.52, BF Gain: 50.88, Critic Loss: 0.07, Policy Loss: -1.12\nBeam: 1, Iter: 30001, Q: 1.7653, Reward pred: -1, Reward: -1, BF Gain pred: 74.85, BF Gain: 15.65, Critic Loss: 0.12, Policy Loss: -0.86\nBeam: 2, Iter: 30001, Q: 1.5752, Reward pred: 1, Reward: -1, BF Gain pred: 115.46, BF Gain: 52.81, Critic Loss: 0.07, Policy Loss: -1.08\nBeam: 3, Iter: 30001, Q: 1.4730, Reward pred: -1, Reward: -1, BF Gain pred: 179.32, BF Gain: 84.74, Critic Loss: 0.06, Policy Loss: -0.92\nTraining for 500 iteration for each Beam uses 28.985605716705322 seconds.\nBeam: 0, Iter: 30501, Q: 1.4968, Reward pred: 1, Reward: -1, BF Gain pred: 172.20, BF Gain: 91.58, Critic Loss: 0.07, Policy Loss: -1.01\nBeam: 1, Iter: 30501, Q: 1.6349, Reward pred: -1, Reward: -1, BF Gain pred: 75.08, BF Gain: 39.34, Critic Loss: 0.15, Policy Loss: -0.72\nBeam: 2, Iter: 30501, Q: 1.7173, Reward pred: -1, Reward: -1, BF Gain pred: 124.80, BF Gain: 70.82, Critic Loss: 0.06, Policy Loss: -1.09\nBeam: 3, Iter: 30501, Q: 1.8612, Reward pred: -1, Reward: -1, BF Gain pred: 168.23, BF Gain: 58.74, Critic Loss: 0.06, Policy Loss: -1.03\nTraining for 500 iteration for each Beam uses 28.57491421699524 seconds.\nBeam: 0, Iter: 31001, Q: 1.5829, Reward pred: -1, Reward: -1, BF Gain pred: 165.98, BF Gain: 65.17, Critic Loss: 0.07, Policy Loss: -1.10\nBeam: 1, Iter: 31001, Q: 2.0216, Reward pred: -1, Reward: -1, BF Gain pred: 79.82, BF Gain: 42.01, Critic Loss: 0.11, Policy Loss: -0.95\nBeam: 2, Iter: 31001, Q: 1.5516, Reward pred: -1, Reward: -1, BF Gain pred: 114.84, BF Gain: 32.48, Critic Loss: 0.07, Policy Loss: -1.17\nBeam: 3, Iter: 31001, Q: 1.8580, Reward pred: -1, Reward: -1, BF Gain pred: 176.60, BF Gain: 54.10, Critic Loss: 0.04, Policy Loss: -0.89\nTraining for 500 iteration for each Beam uses 29.065632104873657 seconds.\nBeam: 0, Iter: 31501, Q: 1.4904, Reward pred: -1, Reward: -1, BF Gain pred: 168.63, BF Gain: 81.65, Critic Loss: 0.07, Policy Loss: -1.09\nBeam: 1, Iter: 31501, Q: 1.4666, Reward pred: 1, Reward: -1, BF Gain pred: 72.28, BF Gain: 25.45, Critic Loss: 0.17, Policy Loss: -0.79\nBeam: 2, Iter: 31501, Q: 1.5728, Reward pred: 1, Reward: -1, BF Gain pred: 138.78, BF Gain: 63.55, Critic Loss: 0.05, Policy Loss: -1.15\nBeam: 3, Iter: 31501, Q: 1.5732, Reward pred: 1, Reward: -1, BF Gain pred: 194.51, BF Gain: 97.89, Critic Loss: 0.06, Policy Loss: -0.93\nTraining for 500 iteration for each Beam uses 29.007792949676514 seconds.\nBeam: 0, Iter: 32001, Q: 1.5928, Reward pred: -1, Reward: -1, BF Gain pred: 173.87, BF Gain: 121.69, Critic Loss: 0.08, Policy Loss: -1.07\nBeam: 1, Iter: 32001, Q: 1.6145, Reward pred: -1, Reward: -1, BF Gain pred: 76.05, BF Gain: 40.42, Critic Loss: 0.11, Policy Loss: -0.99\nBeam: 2, Iter: 32001, Q: 1.3791, Reward pred: -1, Reward: -1, BF Gain pred: 128.71, BF Gain: 44.60, Critic Loss: 0.06, Policy Loss: -1.05\nBeam: 3, Iter: 32001, Q: 1.6946, Reward pred: -1, Reward: -1, BF Gain pred: 152.38, BF Gain: 44.47, Critic Loss: 0.03, Policy Loss: -1.06\nTraining for 500 iteration for each Beam uses 29.25905203819275 seconds.\nBeam: 0, Iter: 32501, Q: 1.6090, Reward pred: -1, Reward: -1, BF Gain pred: 182.40, BF Gain: 102.96, Critic Loss: 0.07, Policy Loss: -1.06\nBeam: 1, Iter: 32501, Q: 1.4658, Reward pred: 1, Reward: -1, BF Gain pred: 80.04, BF Gain: 35.21, Critic Loss: 0.17, Policy Loss: -0.77\nBeam: 2, Iter: 32501, Q: 1.4500, Reward pred: 1, Reward: -1, BF Gain pred: 133.53, BF Gain: 29.67, Critic Loss: 0.05, Policy Loss: -1.04\nBeam: 3, Iter: 32501, Q: 1.6094, Reward pred: 1, Reward: -1, BF Gain pred: 202.10, BF Gain: 68.16, Critic Loss: 0.06, Policy Loss: -1.03\nTraining for 500 iteration for each Beam uses 28.76299285888672 seconds.\nBeam: 0, Iter: 33001, Q: 1.5034, Reward pred: -1, Reward: -1, BF Gain pred: 169.07, BF Gain: 55.53, Critic Loss: 0.07, Policy Loss: -1.11\nBeam: 1, Iter: 33001, Q: 0.4026, Reward pred: -1, Reward: -1, BF Gain pred: 79.96, BF Gain: 37.70, Critic Loss: 0.44, Policy Loss: -0.09\nBeam: 2, Iter: 33001, Q: 1.4891, Reward pred: -1, Reward: -1, BF Gain pred: 128.77, BF Gain: 80.19, Critic Loss: 0.06, Policy Loss: -1.11\nBeam: 3, Iter: 33001, Q: 1.7714, Reward pred: -1, Reward: -1, BF Gain pred: 165.89, BF Gain: 96.25, Critic Loss: 0.06, Policy Loss: -1.05\nTraining for 500 iteration for each Beam uses 28.750367641448975 seconds.\nBeam: 0, Iter: 33501, Q: 1.6450, Reward pred: 1, Reward: -1, BF Gain pred: 168.03, BF Gain: 106.73, Critic Loss: 0.07, Policy Loss: -1.02\nBeam: 1, Iter: 33501, Q: 1.5485, Reward pred: -1, Reward: -1, BF Gain pred: 78.99, BF Gain: 22.81, Critic Loss: 0.16, Policy Loss: -0.70\nBeam: 2, Iter: 33501, Q: 1.5818, Reward pred: 1, Reward: -1, BF Gain pred: 137.06, BF Gain: 81.30, Critic Loss: 0.06, Policy Loss: -1.03\nBeam: 3, Iter: 33501, Q: 1.4515, Reward pred: 1, Reward: -1, BF Gain pred: 181.02, BF Gain: 57.94, Critic Loss: 0.05, Policy Loss: -1.10\nTraining for 500 iteration for each Beam uses 29.04877781867981 seconds.\nBeam: 0, Iter: 34001, Q: 1.5277, Reward pred: 1, Reward: -1, BF Gain pred: 160.13, BF Gain: 68.79, Critic Loss: 0.07, Policy Loss: -1.06\nBeam: 1, Iter: 34001, Q: 1.7140, Reward pred: -1, Reward: -1, BF Gain pred: 73.75, BF Gain: 18.04, Critic Loss: 0.12, Policy Loss: -0.95\nBeam: 2, Iter: 34001, Q: 1.7372, Reward pred: -1, Reward: -1, BF Gain pred: 125.96, BF Gain: 47.06, Critic Loss: 0.07, Policy Loss: -1.07\nBeam: 3, Iter: 34001, Q: 1.6962, Reward pred: -1, Reward: -1, BF Gain pred: 176.78, BF Gain: 95.74, Critic Loss: 0.04, Policy Loss: -1.09\nTraining for 500 iteration for each Beam uses 28.768391847610474 seconds.\nBeam: 0, Iter: 34501, Q: 1.2569, Reward pred: 1, Reward: -1, BF Gain pred: 180.93, BF Gain: 102.77, Critic Loss: 0.07, Policy Loss: -1.12\nBeam: 1, Iter: 34501, Q: 1.3385, Reward pred: -1, Reward: -1, BF Gain pred: 76.33, BF Gain: 43.96, Critic Loss: 0.23, Policy Loss: -0.71\nBeam: 2, Iter: 34501, Q: 1.6312, Reward pred: -1, Reward: -1, BF Gain pred: 129.79, BF Gain: 59.69, Critic Loss: 0.07, Policy Loss: -1.14\nBeam: 3, Iter: 34501, Q: 1.4309, Reward pred: -1, Reward: -1, BF Gain pred: 176.08, BF Gain: 96.78, Critic Loss: 0.08, Policy Loss: -1.19\nTraining for 500 iteration for each Beam uses 28.727149486541748 seconds.\nBeam: 0, Iter: 35001, Q: 1.7442, Reward pred: 1, Reward: -1, BF Gain pred: 177.60, BF Gain: 93.84, Critic Loss: 0.07, Policy Loss: -1.04\nBeam: 1, Iter: 35001, Q: 1.4163, Reward pred: -1, Reward: -1, BF Gain pred: 73.62, BF Gain: 39.29, Critic Loss: 0.13, Policy Loss: -0.94\nBeam: 2, Iter: 35001, Q: 3.0402, Reward pred: -1, Reward: -1, BF Gain pred: 132.57, BF Gain: 39.57, Critic Loss: 0.07, Policy Loss: -1.06\nBeam: 3, Iter: 35001, Q: 1.4513, Reward pred: -1, Reward: -1, BF Gain pred: 184.81, BF Gain: 87.36, Critic Loss: 0.05, Policy Loss: -1.21\nTraining for 500 iteration for each Beam uses 28.572331190109253 seconds.\nBeam: 0, Iter: 35501, Q: 1.4438, Reward pred: 1, Reward: -1, BF Gain pred: 174.21, BF Gain: 88.54, Critic Loss: 0.07, Policy Loss: -0.99\nBeam: 1, Iter: 35501, Q: 1.0222, Reward pred: -1, Reward: -1, BF Gain pred: 73.27, BF Gain: 25.30, Critic Loss: 0.19, Policy Loss: -0.62\nBeam: 2, Iter: 35501, Q: 1.4353, Reward pred: 1, Reward: -1, BF Gain pred: 128.95, BF Gain: 56.34, Critic Loss: 0.05, Policy Loss: -0.95\nBeam: 3, Iter: 35501, Q: 1.4753, Reward pred: -1, Reward: -1, BF Gain pred: 173.73, BF Gain: 94.21, Critic Loss: 0.07, Policy Loss: -1.07\nTraining for 500 iteration for each Beam uses 29.080817461013794 seconds.\nBeam: 0, Iter: 36001, Q: 1.5753, Reward pred: -1, Reward: -1, BF Gain pred: 179.55, BF Gain: 94.07, Critic Loss: 0.08, Policy Loss: -0.99\nBeam: 1, Iter: 36001, Q: 1.0120, Reward pred: 1, Reward: -1, BF Gain pred: 82.72, BF Gain: 42.63, Critic Loss: 0.30, Policy Loss: -0.51\nBeam: 2, Iter: 36001, Q: 1.5010, Reward pred: 1, Reward: -1, BF Gain pred: 124.19, BF Gain: 53.54, Critic Loss: 0.06, Policy Loss: -1.08\nBeam: 3, Iter: 36001, Q: 1.5664, Reward pred: -1, Reward: -1, BF Gain pred: 162.95, BF Gain: 87.86, Critic Loss: 0.05, Policy Loss: -1.16\nTraining for 500 iteration for each Beam uses 29.34126591682434 seconds.\nBeam: 0, Iter: 36501, Q: 1.6474, Reward pred: 1, Reward: -1, BF Gain pred: 180.17, BF Gain: 86.30, Critic Loss: 0.07, Policy Loss: -1.10\nBeam: 1, Iter: 36501, Q: 1.7064, Reward pred: 1, Reward: -1, BF Gain pred: 82.10, BF Gain: 53.04, Critic Loss: 0.13, Policy Loss: -0.90\nBeam: 2, Iter: 36501, Q: 1.7296, Reward pred: -1, Reward: -1, BF Gain pred: 120.96, BF Gain: 52.14, Critic Loss: 0.06, Policy Loss: -1.07\nBeam: 3, Iter: 36501, Q: 1.3408, Reward pred: 1, Reward: -1, BF Gain pred: 176.35, BF Gain: 72.66, Critic Loss: 0.06, Policy Loss: -1.17\nTraining for 500 iteration for each Beam uses 29.17673897743225 seconds.\nBeam: 0, Iter: 37001, Q: 1.5146, Reward pred: 1, Reward: -1, BF Gain pred: 169.51, BF Gain: 94.72, Critic Loss: 0.07, Policy Loss: -1.05\nBeam: 1, Iter: 37001, Q: 1.2999, Reward pred: 1, Reward: -1, BF Gain pred: 81.42, BF Gain: 55.72, Critic Loss: 0.19, Policy Loss: -0.67\nBeam: 2, Iter: 37001, Q: 1.5415, Reward pred: -1, Reward: -1, BF Gain pred: 119.72, BF Gain: 40.46, Critic Loss: 0.05, Policy Loss: -1.01\nBeam: 3, Iter: 37001, Q: 1.6025, Reward pred: -1, Reward: -1, BF Gain pred: 176.40, BF Gain: 43.78, Critic Loss: 0.07, Policy Loss: -1.09\nTraining for 500 iteration for each Beam uses 29.125200510025024 seconds.\nBeam: 0, Iter: 37501, Q: 1.6805, Reward pred: 1, Reward: -1, BF Gain pred: 168.76, BF Gain: 74.35, Critic Loss: 0.06, Policy Loss: -1.03\nBeam: 1, Iter: 37501, Q: 1.4078, Reward pred: 1, Reward: -1, BF Gain pred: 82.66, BF Gain: 53.05, Critic Loss: 0.12, Policy Loss: -0.80\nBeam: 2, Iter: 37501, Q: 1.5546, Reward pred: -1, Reward: -1, BF Gain pred: 116.88, BF Gain: 46.32, Critic Loss: 0.05, Policy Loss: -1.17\nBeam: 3, Iter: 37501, Q: 1.4586, Reward pred: -1, Reward: -1, BF Gain pred: 177.01, BF Gain: 69.23, Critic Loss: 0.06, Policy Loss: -1.06\nTraining for 500 iteration for each Beam uses 29.132648229599 seconds.\nBeam: 0, Iter: 38001, Q: 1.6676, Reward pred: 1, Reward: -1, BF Gain pred: 178.58, BF Gain: 105.97, Critic Loss: 0.06, Policy Loss: -1.10\nBeam: 1, Iter: 38001, Q: 1.5456, Reward pred: 1, Reward: -1, BF Gain pred: 84.66, BF Gain: 60.50, Critic Loss: 0.12, Policy Loss: -0.89\nBeam: 2, Iter: 38001, Q: 1.5716, Reward pred: -1, Reward: -1, BF Gain pred: 115.78, BF Gain: 43.94, Critic Loss: 0.07, Policy Loss: -1.11\nBeam: 3, Iter: 38001, Q: 2.4179, Reward pred: 1, Reward: -1, BF Gain pred: 169.70, BF Gain: 64.30, Critic Loss: 0.08, Policy Loss: -1.24\nTraining for 500 iteration for each Beam uses 29.28290843963623 seconds.\nBeam: 0, Iter: 38501, Q: 1.4010, Reward pred: 1, Reward: -1, BF Gain pred: 178.31, BF Gain: 74.40, Critic Loss: 0.05, Policy Loss: -1.03\nBeam: 1, Iter: 38501, Q: 1.3644, Reward pred: 1, Reward: -1, BF Gain pred: 77.52, BF Gain: 31.53, Critic Loss: 0.13, Policy Loss: -0.89\nBeam: 2, Iter: 38501, Q: 1.4457, Reward pred: -1, Reward: -1, BF Gain pred: 130.86, BF Gain: 62.65, Critic Loss: 0.04, Policy Loss: -1.12\nBeam: 3, Iter: 38501, Q: 1.6738, Reward pred: -1, Reward: -1, BF Gain pred: 179.57, BF Gain: 73.46, Critic Loss: 0.08, Policy Loss: -1.10\nTraining for 500 iteration for each Beam uses 29.028661489486694 seconds.\nBeam: 0, Iter: 39001, Q: 1.8395, Reward pred: 1, Reward: -1, BF Gain pred: 180.23, BF Gain: 97.57, Critic Loss: 0.07, Policy Loss: -1.08\nBeam: 1, Iter: 39001, Q: 1.5835, Reward pred: 1, Reward: -1, BF Gain pred: 82.37, BF Gain: 38.89, Critic Loss: 0.10, Policy Loss: -1.05\nBeam: 2, Iter: 39001, Q: 1.3576, Reward pred: -1, Reward: -1, BF Gain pred: 125.37, BF Gain: 71.49, Critic Loss: 0.06, Policy Loss: -1.04\nBeam: 3, Iter: 39001, Q: 1.6844, Reward pred: 1, Reward: -1, BF Gain pred: 179.63, BF Gain: 63.50, Critic Loss: 0.07, Policy Loss: -1.29\nTraining for 500 iteration for each Beam uses 28.660950660705566 seconds.\nBeam: 0, Iter: 39501, Q: 1.7232, Reward pred: -1, Reward: -1, BF Gain pred: 156.01, BF Gain: 50.83, Critic Loss: 0.08, Policy Loss: -0.98\nBeam: 1, Iter: 39501, Q: 1.6384, Reward pred: 1, Reward: -1, BF Gain pred: 80.74, BF Gain: 43.36, Critic Loss: 0.16, Policy Loss: -1.04\nBeam: 2, Iter: 39501, Q: 1.5209, Reward pred: -1, Reward: -1, BF Gain pred: 133.76, BF Gain: 83.91, Critic Loss: 0.05, Policy Loss: -1.07\nBeam: 3, Iter: 39501, Q: 3.0562, Reward pred: 1, Reward: -1, BF Gain pred: 184.26, BF Gain: 103.98, Critic Loss: 0.07, Policy Loss: -1.26\nTraining for 500 iteration for each Beam uses 28.91983962059021 seconds.\nBeam: 0, Iter: 40001, Q: 1.3603, Reward pred: -1, Reward: -1, BF Gain pred: 161.35, BF Gain: 90.57, Critic Loss: 0.07, Policy Loss: -1.00\nBeam: 1, Iter: 40001, Q: 1.6302, Reward pred: -1, Reward: -1, BF Gain pred: 77.12, BF Gain: 39.74, Critic Loss: 0.10, Policy Loss: -1.11\nBeam: 2, Iter: 40001, Q: 1.9010, Reward pred: 1, Reward: -1, BF Gain pred: 127.74, BF Gain: 59.52, Critic Loss: 0.04, Policy Loss: -1.12\nBeam: 3, Iter: 40001, Q: 1.5330, Reward pred: -1, Reward: -1, BF Gain pred: 162.30, BF Gain: 54.37, Critic Loss: 0.06, Policy Loss: -1.33\nTraining for 500 iteration for each Beam uses 29.993797540664673 seconds.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport scipy.io as scio\n\nnum_ant = 32\nnum_beam = 4\nresults = np.empty((num_beam, 2*num_ant))\n\npath = './beams/'\n\nfor beam_id in range(num_beam):\n    fname = 'beams_' + str(beam_id) + '_max.txt'\n    with open(path + fname, 'r') as f:\n        lines = f.readlines()\n        last_line = lines[-1]\n        results[beam_id, :] = np.fromstring(last_line.replace(\"\\n\", \"\"), sep=',').reshape(1, -1)\n\nresults = (1 / np.sqrt(num_ant)) * (results[:, ::2] + 1j * results[:, 1::2])\n\nscio.savemat('beam_codebook.mat', {'beams': results})","metadata":{"execution":{"iopub.status.busy":"2023-10-06T10:01:30.518936Z","iopub.execute_input":"2023-10-06T10:01:30.519420Z","iopub.status.idle":"2023-10-06T10:01:30.531767Z","shell.execute_reply.started":"2023-10-06T10:01:30.519381Z","shell.execute_reply":"2023-10-06T10:01:30.530541Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nplt.title(f'Best beamforming gain')\nplt.xlabel('Beam_framing_gain')   \nfor beam_id in range(options['num_NNs']):\n    gain_record=np.concatenate(env_list[beam_id].gain_record[1:]).flatten()\n    plt.plot(gain_record, label=f'Beam_{beam_id}')\n    plt.plot([])\nplt.plot([231.17094]*50,linestyle='dashed',color='black')\nplt.legend(loc=\"upper left\")  \nplt.show()    ","metadata":{"execution":{"iopub.status.busy":"2023-10-06T10:01:30.533654Z","iopub.execute_input":"2023-10-06T10:01:30.534468Z","iopub.status.idle":"2023-10-06T10:01:31.031622Z","shell.execute_reply.started":"2023-10-06T10:01:30.534429Z","shell.execute_reply":"2023-10-06T10:01:31.030571Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]}]}