{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import SGD"
      ],
      "metadata": {
        "id": "rJJfuD7OVPHu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "# assert x_train.shape == (50000, 32, 32, 3)\n",
        "# assert x_test.shape == (10000, 32, 32, 3)\n",
        "# assert y_train.shape == (50000, 1)\n",
        "# assert y_test.shape == (10000, 1)"
      ],
      "metadata": {
        "id": "klu7RC_ZVQGF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "  # load dataset\n",
        "  (trainX, trainY), (testX, testY) = tf.keras.datasets.cifar10.load_data()\n",
        "  # one hot encode target values\n",
        "  trainY = to_categorical(trainY)\n",
        "  testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "  # convert from integers to floats\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "  # normalize to range 0-1\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  # return normalized images\n",
        "  return train_norm, test_norm"
      ],
      "metadata": {
        "id": "yF_02610Vpuz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  # compile model\n",
        "  opt_ = SGD(lr=1e-2, momentum=0.9)\n",
        "  opt = tf.keras.optimizers.Adam(epsilon=1e-2)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "Jovh1408WoqP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_diagnostics(history):\n",
        "  # plot loss\n",
        "  pyplot.subplot(211)\n",
        "  pyplot.title('Cross Entropy Loss')\n",
        "  pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "  pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "  # plot accuracy\n",
        "  pyplot.subplot(212)\n",
        "  pyplot.title('Classification Accuracy')\n",
        "  pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "  pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "  # save plot to file\n",
        "  filename = sys.argv[0].split('/')[-1]\n",
        "  pyplot.savefig(filename + '_plot.png')\n",
        "  pyplot.close()\n",
        "\n",
        "def run_test_harness():\n",
        "  # load dataset\n",
        "  trainX, trainY, testX, testY = load_dataset()\n",
        "  # prepare pixel data\n",
        "  trainX, testX = prep_pixels(trainX, testX)\n",
        "  # define model\n",
        "  model = define_model()\n",
        "  # fit model\n",
        "  history = model.fit(trainX, trainY, epochs=2, batch_size=32, validation_data=(testX, testY))\n",
        "  # evaluate model\n",
        "  _, acc = model.evaluate(testX, testY, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "  # learning curves\n",
        "  summarize_diagnostics(history)"
      ],
      "metadata": {
        "id": "AZ0oLy3CW86z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3DulLzoXHWb",
        "outputId": "3cc7dadc-cfbb-4123-db81-aaf181d267a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 26s 8ms/step - loss: 1.3756 - accuracy: 0.5070 - val_loss: 1.5376 - val_accuracy: 0.4654\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.9513 - accuracy: 0.6627 - val_loss: 1.0712 - val_accuracy: 0.6400\n",
            "> 64.000\n"
          ]
        }
      ]
    }
  ]
}